---
title: "Impact Factor"
author: "Michael Betancourt"
date: "January 2021"
bibliography: factor_modeling.bib
csl: institute-of-mathematical-statistics.csl
link-citations: yes
linkcolor: blue
output:
  html_document:
    fig_caption: yes
    theme: spacelab #sandstone #spacelab #flatly
    highlight: pygments
    toc: TRUE
    toc_depth: 3
    number_sections: TRUE
    toc_float:
      smooth_scroll: FALSE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment=NA)
knitr::opts_knit$set(global.par = TRUE)
```

<!-- form factor -->
<!-- impact factor -->
<!-- risk factor -->
<!-- wow factor -->
<!-- fear factor -->

Hierarchical models are a natural way to model heterogeneity across exchangeable
contexts, but they become less appropriate when additional information
discriminates those contexts.  In particular any labels that categorize
individual contexts into groups immediately obstructs the full exchangeability,
and modeling heterogeneity consistently with these groupings becomes much more
subtle. When the contexts are subject to multiple, overlapping categorizations
the challenge becomes even more difficult.  In this case study we investigate
how to generalize exchangeability in the presence of _factors_ that categorize
individual contexts and then develop modeling techniques compatible with this
generalization.

We begin by discussing how to consistently model heterogeneity in the presence
of a single factor before considering multiple factors, in particular multiple
factors whose groups nest within each other and multiple factors whose groups
overlap.  With this foundation laid we then demonstrate the basic implementation
and analysis of these models before working through some more realistic
examples.

# Single Factor Models {#sec:single_factor}

Let's begin by considering how heterogeneity manifests in the presence of a
single categorizing variable.  After defining these categorizing variables as
factors we discuss the conditional and marginal exchangeability compatible with
categorical groups and the resulting hierarchical models.  Finally we reframe
these hierarchies in terms of residual variations across the groups.

## Factors

As we saw in my [hierarchical modeling case study](https://betanalpha.github.io/assets/case_studies/hierarchical_modeling.html)
a set of individual contexts are exchangeable only when we do not have, or
ignore, any information that discriminates one context from another.  For
example the cards in a deck are exchangeable when we can view only their back
faces.

<center>
<br>
```{r, out.width = "50%", echo=FALSE}
knitr::include_graphics("figures/one_factor_pickup_backs/one_factor_pickup_backs.png")
```
<br><br>
</center>

Flipping the cars over, however, reveals patterns that break the full
exchangeability of the cards.

<center>
<br>
```{r, out.width = "50%", echo=FALSE}
knitr::include_graphics("figures/one_factor_pickup/one_factor_pickup.png")
```
<br><br>
</center>

We will denote such discriminating information with traditional statistics
terminology.  A _factor_ is a categorical variable that endows each context with
one of a finite number of discrete, unordered values, or _levels_.  When there
is minimal risk of confusion I will also use "level" to refer to all of the
individual contexts grouped with the same level value.  In our card example the
immediate factor is color, with the three levels corresponding to light red,
red, and dark red values.  The "dark red level" would then correspond to all
cards with dark red coloring.

Factors can capture any abstract categorization or labeling.  For example if the
contexts are defined by facilities where a certain product is manufactured then
a region factor might assign values of "northeast", "southeast", southwest", and
"northwest" depending on where each factory is located.  Additional factors
might include where the material input to the manufacturing process is sourced,
environmental conditions, and even manager and employee assignments.

## Conditional and Marginal Exchangeability

Regardless of its interpretation, the level assignments within a factor obstruct
some of the permutations that would be valid without the factor.  In particular
although our information is still indifferent to permutations of cards _within
the same level_ we will notice permutations of cards _within different levels_.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/one_factor_pickup_permute/one_factor_pickup_permute.png")
```
<br><br>
</center>

Grouping the individual contexts by their level assignments makes it easier to
identify, and classify, the permutations that persist after a factor has been
introduced.  For example the permutations that modify only contexts within a
single level are unaffected by the introduction of the factor and they define a
 _conditional exchangeability_.

<center>
<br>
```{r, out.width = "50%", echo=FALSE}
knitr::include_graphics("figures/one_factor_sorted/one_factor_sorted.png")
```
<br><br>
</center>

These conditional exchangeabilities then suggests that the heterogeneity of the
individual contexts should be modeled with independent hierarchical models
within each level.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/one_factor_sorted_hier_conditional/one_factor_sorted_hier_conditional.png")
```
<br><br>
</center>

Because the level values themselves are also arbitrary labels, any permutation
that swaps _all_ of the contexts within different levels is also compatible with
the given factor.  These permutations then define a corresponding
_marginal exchangeability_.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/one_factor_marginal/one_factor_marginal.png")
```
<br><br>
</center>

Consequently any behavior common to each level is naturally modeled with a
hierarchical model _across_ the levels.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/one_factor_sorted_hier_marginal/one_factor_sorted_hier_marginal.png")
```
<br><br>
</center>

## Factor Compatible Hierarchical Models {#sec:single_factor_model}

Conditional exchangeability motivates independent hierarchical models within
each of the factor levels, while marginal exchangeability motivates a
hierarchical model across the factor levels.  These residual exchangeabilities,
however, are compatible with each other.  Consequently the hierarchies can be
combined into a _deeper_ hierarchical model with multiple layers, the top level
capturing the conditional heterogeneity and the bottom layer capturing the
marginal heterogeneity across levels.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/one_factor_sorted_hier_both/one_factor_sorted_hier_both.png")
```
<br><br>
</center>

This architecture gives the most general family of hierarchical models
compatible with a given factor.  In order to specify a particular hierarchical
model we first need to specify the population models within each level,
$$
\theta_{k} \sim \pi(\phi_{l(k)}),
$$
where $k \in \{1, \ldots, K_{l} \}$ indexes the individual contexts,
$l \in \{1, \ldots, L\}$ indexes each factor level, and $l(k)$ maps each context
into its associated factor level.  The full model specification is then
completed with a population model across the level-specific population
parameters,
$$
\phi_{l} \sim \pi(\phi).
$$

For example within each level we might consider a normal population model,
$$
\theta_{k} \sim \text{normal}(\theta_{l(k)}, \tau_{l(k)}).
$$
In general we can pool the population parameters $(\theta_{l}$, $\tau_{l})$
jointly with a two-dimensional population model, but we might also pool just the
level-specific location parameters, $\theta_{l}$, or the level-specific scale
parameters, $\tau_{l}$, with one-dimensional hierarchical models.  We might for
instance pool only the location parameters with another normal
population model,
$$
\theta_{l} \sim \text{normal}(\mu, \tau).
$$
Together these assumptions specify a basic, but effective, factor compatible
hierarchical model,
$$
\begin{align*}
\theta_{k} &\sim \text{normal}(\theta_{l(k)}, \tau_{l(k)})
\\
\theta_{l} &\sim \text{normal}(\mu, \tau).
\end{align*}
$$

That said, this specific hierarchical model doesn't actually appear much in the
statistics literature.  Most commonly the conditional heterogeneity within the
levels is implicitly ignored, or occasionally explicitly assumed to be zero.  In
either case all of the individual contexts collapse into a set of
_level contexts_, and the remaining marginal heterogeneity across those level
contexts is captured by a single hierarchical model,
$$
\theta_{l} \sim \pi(\phi).
$$
For example given the normal assumptions from above we might have
$$
\theta_{l} \sim \text{normal}(\mu, \tau).
$$
From this perspective the full factor-compatible hierarchical model that
includes the within-level heterogeneity becomes a special case of _nested factor
model_ which we will discuss in depth in [Section 2](#sec:nested_multifactor).

To avoid too much confusion with the literature, from here on we will by default
also ignore the conditional heterogeneity within the factor levels so that the
heterogeneity compatible with a factor is naturally modeled by a single,
one-layer hierarchical model.

## Residual Hierarchical Models {#sec:single_residual}

When building our first factor compatible hierarchical model above we exploited
the interpretability of the monolithically centered parameterization,
$$
\theta_{l} \sim \text{normal}(\theta, \tau).
$$
Once we have specified the model we may have to consider non-centering some or
even all of the level parameters as needed to ensure accurate computation in
practice.

One particular reparameterization, however, also offers a useful
interpretability that can facilitate model building.  If we non-center the level
parameters _with respect to the location parameter_ then the hierarchical model
takes on a particularly compelling form:
$$
\begin{align*}
\theta_{l} &= \theta + \delta_{l}
\\
\delta_{l} &\sim \text{normal}(0, \tau).
\end{align*}
$$
The behavior within each level decomposes into _additive_ contribution from a
common baseline $\theta$ plus a residual $\delta_{l}$ that captures the
variation across levels.

This residual perspective can also be useful when building more general factor
compatible hierarchical models.  If the parameters $\theta_{l}$ are
unconstrained then we can always mathematically decompose the behavior of each
individual context into a baseline behavior with residual corrections.  All we
have to do is add and subtract a common baseline contribution,
$$
\begin{align*}
\theta_{l}
&=
\theta_{l} + 0
\\
&=
\theta_{l} + (-\theta + \theta)
\\
&=
(\theta_{l} - \theta) + \theta,
\\
&=
\delta_{l} + \theta.
\end{align*}
$$
Keep in mind that this residual decomposition is not always possible, especially
when the behavior in each context is modeled with a single constrained parameter
or multiple coupled parameters.

Assuming that each set of residual parameters are exchangeable motivates another
hierarchical model,
$$
\begin{align*}
\theta_{l} &= \delta_{l} + \theta
\\
\delta_{l} &\sim \pi(\phi).
\end{align*}
$$
Taking normal population models exactly recovers the normal hierarchical model
from above, but this approach can provide a convenient way to engineer more
general hierarchical models that also maintain marginal exchangeability.  Of
course once we build a model this way we may still have to consider
reparameterizations when fitting the model in practice.

One subtlety introduced with this residual construction is the interpretation of
the parameters themselves, which are defined only _relative_ to each other.
Because neither the baseline nor the residual contributions influence the data
generating process independently of the other they have no _independent_
meaning.  In order to reconstruct the behavior in any observed context,
$\theta_{l}$, we have to incorporate both $\theta$ and $\delta_{l}$ together.

That said the residual parameters are often implicitly given an interpretation
based on _counterfactual_ circumstances.  For example the baseline $\theta$
might be presented as the behavior of a _hypothetical_ level with
$delta_{l} = 0$,
$$
\theta_{l} = \theta + 0.
$$
Although we might not observe this circumstance, and indeed it might be
impossible to observe this circumstance at all, it provides _an_ interpretation
for $\theta$ independent of the other parameters.  Similarly the factor level
residuals might be interpreted as the behavior within each level in the
hypothetical circumstance where the baseline contribution vanishes,
$$
\theta_{l} = 0 + \delta_{l}.
$$

Personally I find these counterfactual interpretations confusing if not outright
misleading, especially when they are made implicitly.  I recommend instead
always using _explicit_ configurations to interpret the residual parameters.
That configuration might be _actual_, corresponding to levels observed in the
data, or _hypothetical_, corresponding to hypothetical levels with hypothetical
behavior.  By making these assumptions explicit we avoid any ambiguity in
statements about the parameters, and hence any confusion in how those statements
might apply in other circumstances.  In particular writing out the full
assumptions can make it clear when hypothetical assumptions are particularly
irrelevant or misleading.

# Nested Multifactor Models {#sec:nested_multifactor}

The information encoded in a single factor complicates notions of
exchangeability and, consequently, the modeling of heterogeneity compatible with
that information.  Unsurprisingly incorporating _multiple_ factors complicates
matters further still.  Let's first consider multifactor models where each
factor is compatible with each other.

## Nested Hierarchies

In particular consider a sequence of factors that _nest_ within each other,
where the levels of each successive factor only subdivides the levels of the
previous factor.  More formally each successive factor has strictly more levels
than the proceeding factor, and those factor levels fall into one and only one
of the proceeding factor levels.

For example we might have a deck of cards that are characterized by not just
colors but also symbols.

<center>
<br>
```{r, out.width = "50%", echo=FALSE}
knitr::include_graphics("figures/two_factor_nested_pickup/two_factor_nested_pickup.png")
```
<br><br>
</center>

As before the color factor groups the individual contexts into color levels,
reducing the full exchangeability into marginal exchangeability across the
color levels and conditional exchangeability within the color levels.  As above
we will assume that there is no heterogeneity within the levels so that the
structure of the factor compatible hierarchical model is determined entirely by
the marginal exchangeability.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_nested_color/two_factor_nested_color.png")
```
<br><br>
</center>

The new symbol factor also groups the individual contexts, but this time into
symbol levels.  These symbol levels then motivate their own own factor
compatible hierarchical models.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_nested_symbol/two_factor_nested_symbol.png")
```
<br><br>
</center>

If we look closely, however, we see that the symbol levels nest within the color
levels, subdividing the color levels but not crossing them.  Consequently the
exchangeabilities induced by these two factors are compatible with each other.
The full exchangeability of the individual contexts separates into marginal
exchangeability across the color levels, a marginal/conditional exchangeability
across the symbol levels nested within each color level, and then finally the
fully conditional exchangeability within the symbol levels.

Because the exchangeabilities are compatible so too are the two factor
compatible hierarchical models.  In particular the symbol hierarchies nest
within the color hierarchy to form a deeper hierarchical model.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_nested_nested/two_factor_nested_nested.png")
```
<br><br>
</center>

In this case by ignoring the conditional heterogeneity within the symbol levels
the individual contexts collapse into one context for each symbol.  This holds
more generally -- the relevant contexts in a nested multifactor model are always
the levels of the _shallowest_ factor with the most refined levels.

For example consider an initial factor $f_{1}$ that separates the individual
contexts into the levels $l_{1} \in \{1, \ldots, L_{f_{1}}\}$, and then a second
factor $f_{2}$ that separates the contexts into the levels
$l_{2} \in \{1, \ldots, L_{f_{2}} \}$ that nest into the $f_{1}$ levels with the
many-to-one map $l_{1}(l_{2})$.  The most general family of hierarchical models
compatible with these two nested factors is given by
$$
\begin{align*}
\theta^{f_{2}}_{l_{2}} &\sim \pi( \theta^{f_{1}}_{l_{1}(l_{2})} )
\\
\theta^{f_{1}}_{l_{1}} &\sim \pi(\phi).
\end{align*}
$$
If we assume that the heterogeneity manifests _only_ in the location of a normal
population model then we arrive at a nested normal hierarchical model,
$$
\begin{align*}
\theta^{f_{2}}_{l_{2}} &\sim
\text{normal}( \theta^{f_{1}}_{l_{1}(l_{2})}, \tau^{f_{1}}_{l_{1}(l_{2})} )
\\
\theta^{f_{1}}_{l_{1}} &\sim \text{normal}(\theta, \tau).
\end{align*}
$$

One of the more frustrating but also critical aspects of multifactor models is
their organization.  Through this case study I try to communicate that
organization as clearly as possible with a careful, explicit notation.  That
notation, however, also introduces a mess of indices that can be a bit
overwhelming at first.  Hopefully the clarity is worth it!

## Conditional Exchangeability and Trivial Factors

If we do want to include the conditional heterogeneity within the symbol levels
then the hierarchy must extend to the individual contexts as well.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_nested_residual/two_factor_nested_residual.png")
```
<br><br>
</center>

Those individual contexts, however, always defines a natural factor: the
_trivial factor_ that assigns each context to its own level.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_nested_indiv/two_factor_nested_indiv.png")
```
<br><br>
</center>

Because it completely separates the contexts, the trivial factor is always
compatible with other factors no matter how refined their levels might be.
Consequently we can always add another hierarchy to modeling the heterogeneity
across the trivial levels on top of any nested hierarchical model.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_nested_indiv_nested/two_factor_nested_indiv_nested.png")
```
<br><br>
</center>

This final layer, however, recovers the exact same hierarchical structure that
arose when we included the conditional heterogeneity of the most refined
level!  Consequently even if we generally ignore the conditional heterogeneity
within the individual factor levels we can always incorporated it back into the
final nested multifactor model by including an additional trivial factor.  In
particular once we have programs capable of automatically building multifactor
model for any set of nested factors it's straightforward to add the residual
heterogeneity within the more refined level by adding an explicit trivial
factor.  This is perhaps one reason why conditional heterogeneity is often
ignored entirely in many references on multifactor models.

## Nested Residuals

As is often the case we specified the nested normal hierarchical model in a
monolithically centered parameterization,
$$
\begin{align*}
\theta^{f_{2}}_{l_{2}} &\sim
\text{normal}( \theta^{f_{1}}_{l_{1}(l_{2})}, \tau^{f_{1}}_{l_{1}(l_{2})} )
\\
\theta^{f_{1}}_{l_{1}} &\sim \text{normal}(\theta, \tau).
\end{align*}
$$
Equivalently we can also non-center each hierarchical parameter relative to the
corresponding location parameter to give a residual model,
$$
\begin{align*}
\theta^{f_{2}}_{l_{2}} &= \theta + \delta^{f_{1}}_{l_{1}(l_{2})} + \delta^{f_{2}}_{l_{2}}
\\
\delta^{f_{2}}_{l_{2}} &\sim \text{normal}(0, \tau^{f_{1}}_{l_{1}(l_{2})} )
\\
\delta^{f_{1}}_{l_{1}} &\sim \text{normal}(0, \tau).
\end{align*}
$$

As before we can also motivate such a nested residual construction more
generally if all of the hierarchical parameters are unconstrained.  We begin by
adding and subtracting a variable corresponding the levels of the first factor,
$$
\begin{align*}
\theta^{f_{2}}_{l_{2}}
&=
\theta^{f_{2}}_{l_{2}} + 0
\\
&=
\theta^{f_{2}}_{l_{2}} +
\big( -\theta^{f_{1}}_{l_{1}(l_{2})} + \theta^{f_{1}}_{l_{1}(l_{2})} \big)
\\
&=
\big( \theta^{f_{2}}_{l_{2}} - \theta^{f_{1}}_{l_{1}(l_{2})} \big)
+ \theta^{f_{1}}_{l_{1}(l_{2})}.
\end{align*}
$$
Then we add and subtract a term common to all levels,
$$
\begin{align*}
\theta^{f_{2}}_{l_{2}}
&=
\big(\theta^{f_{2}}_{l_{2}} - \theta^{f_{1}}_{l_{1}(l_{2})}\big)
+ \theta^{f_{1}}_{l_{1}(l_{2})} + 0
\\
&=
\big(\theta^{f_{2}}_{l_{2}} - \theta^{f_{1}}_{l_{1}(l_{2})}\big)
+ \theta^{f_{1}}_{l_{1}(l_{2})} + \big( -\theta + \theta \big)
\\
&=
\big( \theta^{f_{2}}_{l_{2}} - \theta^{f_{1}}_{l_{1}(l_{2})} \big)
+ \big( \theta^{f_{1}}_{l_{1}(l_{2})} - \theta \big) + \theta
\\
&=
\hspace{1mm} \delta^{f_{2}}_{l_{2}}
\hspace{18.1mm} + \delta^{f_{1}}_{l_{1}(l_{2})}
\hspace{11.4mm} + \theta.
\end{align*}
$$
We can then build a hierarchical model compatible with the two nested factors by
modeling the residuals that are nested together with independent hierarchical
models.  If the population models in these hierarchies are normal then we
recover the nested normal model above, but again this construction gives us the
freedom to specify more complex hierarchies that might be useful in any given
application.

The residual parameters here suffer the same interpretational difficulties that
we encountered in [Section 1.4](#sec:single_residual).  In order to reconstruct
the behavior in any observed context, $\theta^{f_{2}}_{l_{2}}$, we have to
incorporate _all_ of the contributions, including the baseline $\theta$, the
first factor residuals $\delta^{f_{1}}_{l_{1}(l_{2})}$, and the second factor
residuals, $\delta^{f_{2}}_{l_{2}}$.  Consequently none of these parameters have
any interpretation independent of the others.

We can continue to avoid confusion by always interpreting model inferences in
terms of an explicit context, and the contributions from all of the factors
levels to which that context belongs.  As before those contexts can be actual,
constructed from observed levels and their inferred behavior, or hypothetical,
imagined levels where heterogeneity vanishes.  For example in order to isolate
the baseline we have to consider hypothetical residuals levels with zero
contribution,
$$
\begin{align*}
\delta^{f_{1}}_{l_{1}(l_{2})} &= \delta^{f_{2}}_{l_{2}} = 0
\\
\theta^{f_{2}}_{l_{2}} &= \theta + 0 + 0 = \theta,
\end{align*}
$$
while isolating the first factor contributions require hypothetically
vanishing contributions from the baseline and second factor,
$$
\begin{align*}
\theta &= \delta^{f_{2}}_{l_{2}} = 0,
\\
\theta^{f_{2}}_{l_{2}}
&= 0 + \delta^{f_{1}}_{l_{1}(l_{2})} + 0
= \delta^{f_{1}}_{l_{1}(l_{2})}.
\end{align*}
$$
Finally to isolate only the second factor contributions we have to imagine that
the contributions from both the baseline and first factor vanish,
$$
\begin{align*}
\theta &= \delta^{f_{1}}_{l_{1}(l_{2})} = 0,
\\
\theta^{f_{2}}_{l_{2}}
&= 0 + 0 + \delta^{f_{2}}_{l_{2}}
= \delta^{f_{2}}_{l_{2}}.
\end{align*}
$$

By communicating _all_ of the relevant assumptions we avoid any interpretational
ambiguity.

# Overlapping Multifactor Models

When the levels of multiple factors don't nest, and instead overlap with each
other, building models compatible with all of the factors at the same time
becomes especially challenging.  In this case we often have to appeal to models
that are only _approximately_ compatible with all of the factors.

## Intersecting Exchangeability

Let's look at a deck of cards once again.  The cards continue to be
characterized by color and symbol factors, only this time the symbols levels are
allocated differently.

<center>
<br>
```{r, out.width = "50%", echo=FALSE}
knitr::include_graphics("figures/two_factor_pickup/two_factor_pickup.png")
```
<br><br>
</center>

If we consider only the color factor then our model proceeds as in
[Section 1](#sec:single_factor).  We can freely permute the cards within each
color level, defining conditional exchangeabilities, and all of the cards across
levels, defining marginal exchangeability, and motivating a compatible
hierarchical model.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_sorted_color/two_factor_sorted_color.png")
```
<br><br>
</center>

The symbol factors, however, define a _different_ sense of marginal and
conditional exchangeability and hence a different compatible hierarchical model.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_sorted_symbol/two_factor_sorted_symbol.png")
```
<br><br>
</center>

Because the factor levels overlap, however, these notions of exchangeability are
not consistent with each other.  Many permutations that are compatible the color
factor, for example, are not compatible with the symbol factor categorizations.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_sorted_both/two_factor_sorted_both.png")
```
<br><br>
</center>

The only permutations that are compatible with _both_ factors at the same time
are those confined to the same _intersection level_.

<center>
<br>
```{r, out.width = "50%", echo=FALSE}
knitr::include_graphics("figures/two_factor_sorted_inter/two_factor_sorted_inter.png")
```
<br><br>
</center>

These permutations define an _intersectional exchangeability_ that decomposes
into marginal exchangeability across the intersection levels and conditional
exchangeability within the intersection levels.  This decomposition then defines
the compatible hierarchical models that we're after.

The intersectional marginal exchangeability motivates a hierarchical model
across the intersection levels.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_sorted_inter_hier/two_factor_sorted_inter_hier.png")
```
<br><br>
</center>

Similarly the intersectional conditional exchangeability motivates hierarchical
models nested within the intersection levels to account for the residual
heterogeneity.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_sorted_inter_hier_residual/two_factor_sorted_inter_hier_residual.png")
```
<br><br>
</center>

Per convention we will focus on the marginal exchangeability, ignoring the
conditional exchangeability and hence the residual heterogeneity within the
intersection levels.  We can always incorporate that residual heterogeneity
by explicitly adding a trivial factor to the existing factors.

In order to build these overlapping factor compatible hierarchical models we
first have to build the intersection levels across which the heterogeneity
manifests.  If there are $F$ factors, each with $L_{f}$ levels, then the
number of intersection levels is given by the _product_ of all of the factor
levels,
$$
L_{\text{int}} = \prod_{f = 1}^{F} L_{f}.
$$
For example in our deck example we have three color levels, four symbol levels,
and hence twelve total intersection levels.

If we use these intersection levels to define an _intersection factor_ then the
hierarchical model compatible with all of the factors is straightforward: we
just build a single factor model for the intersection factor as in
[Section 1](#sec:single_factor),
$$
\theta_{l} \sim \text{normal}(\theta, \tau).
$$

## Incremental Intersections {#sec:residual_expansion}

Once we construct the intersection factor building the compatible hierarchical
model is conceptually straightforward.  In practice, however, some critical
problems quickly arise.

Most immediately the number of intersection levels tends to be large.  As we
consider more factors, and more levels within each factor, the total number
of intersections explodes multiplicatively.  Even if each factor features only
a few levels on its own, the intersection factor can easily have hundreds if not
thousands of levels.  As the number of intersection levels grows the occupancy
of the levels also becomes more sparse for any fixed number of observations;
many of the intersection levels might not be observed at all.  At best this
results in weak inferences, and at worst it can result in inferences that are
degenerate enough to obstruct accurate computation.

The intersection levels also manifest strong correlations.  Any behavior common
to a level in one of the factors will propagate to _all_ of the intersection
levels that correspond to that level; the more significant the common behavior
the more strongly those intersection parameters will be coupled together.  For
example any behavior common to the second color level will induce correlations
between all four of the corresponding interaction levels, and any behavior
common to the second symbol level will induce correlations between all three
of the corresponding interaction levels.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/two_factor_inter_corr/two_factor_inter_corr.png")
```
<br><br>
</center>

The common behavior in all of the individual factor levels results in a tangled
web of complex interactions that can frustrate not only computation but also the
interpretation of the parameters.

Taking inspiration from the residual perspective we considered above, however,
we can expand the intersection parameters into a sequence of residual
parameters that may be better behaved.  For example consider the case of two
factors, the first with levels indexed by $l_{1} \in \{1, \ldots, L_{1}\}$, the
second with levels indexed $l_{2} \in \{1, \ldots, L_{2}\}$, and the
corresponding intersection levels indexed by the ordered pair $(l_{1}, l_{2})$.

Notational complaints aside, we can isolate the behavior common to the
individual factor levels by adding and subtracting parameters for each,
$$
\begin{align*}
\theta^{f_{1}, f_{2}}_{l_{1}, l_{2}}
&=
\theta^{f_{1}, f_{2}}_{l_{1}, l_{2}} + 0 + 0
\\
&=
\theta^{f_{1}, f_{2}}_{l_{1}, l_{2}}
+ \big(-\theta^{f_{1}}_{l_{1}} + \theta^{f_{2}}_{l_{2}} \big)
+ \big(-\theta^{f_{1}}_{j} + \theta^{f_{2}}_{l_{2}} \big)
\\
&=
\big(\theta^{f_{1}, f_{2}}_{l_{1}, l_{2}} - \theta^{f_{1}}_{l_{1}} - \theta^{f_{2}}_{l_{2}}\big)
+ \theta^{f_{1}}_{l_{1}} + \theta^{f_{2}}_{l_{2}}.
\end{align*}
$$
We can then isolate the behavior common to all levels by adding and subtracting
a baseline parameter,
$$
\begin{align*}
\theta^{f_{1}, f_{2}}_{l_{1}, l_{2}}
&=
\big(\theta^{f_{1}, f_{2}}_{l_{1}, l_{2}} - \theta^{f_{1}}_{l_{1}} - \theta^{f_{2}}_{l_{2}}\big)
+ \theta^{f_{1}}_{l_{1}} + \theta^{f_{2}}_{l_{2}}
+ 2 \cdot 0
\\
&=
\big(\theta^{f_{1}, f_{2}}_{l_{1}, l_{2}} - \theta^{f_{1}}_{l_{1}} - \theta^{f_{2}}_{l_{2}}\big)
+ \theta^{f_{1}}_{l_{1}} + \theta^{f_{2}}_{l_{2}}
+ 2 \cdot (-\theta + \theta)
\\
&=
\big(\theta^{12}_{l_{1}, l_{2}} - \theta^{f_{1}}_{l_{1}} - \theta^{f_{2}}_{l_{2}} + \theta\big)
+ \big(\theta^{f_{1}}_{l_{1}} - \theta\big)
+ \big(\theta^{f_{2}}_{l_{2}} - \theta\big)
+ \theta
\\
&= 
\hspace{1mm} \delta^{f_{1}, f_{2}}_{l_{1}, l_{2}}
\hspace{31.25mm} + \delta^{f_{1}}_{l_{1}}
\hspace{12.25mm} + \delta^{f_{2}}_{l_{2}}
\hspace{12.5mm} + \theta
\end{align*}
$$

The baseline factor $\theta$ captures the behavior common to all contexts
while the residual factors $\delta^{f_{1}}_{l_{1}}$ and $\delta^{f_{2}}_{l_{2}}$
capture the behavior common to the contexts within each individual factor level.
This leaves the residual interaction factor,
$\delta^{f_{1}, f_{2}}_{l_{1}, l_{2}}$, which captures any excess heterogeneity
unique to the _overlap_ of the factor levels.

If these common behaviors are significant then these residual parameters should
be less strongly coupled then the original intersection parameters.  Moreover
even if the intersection levels are sparsely populated the baseline and factor
residuals will tend to be more densely populated and hence easier to infer.

In general we can decompose the intersection of $N_{F}$ factors into a single
baseline, main contributions from each factor, first-order interactions between
each pair of factors, second-order interactions between each triplet of factors,
and so on.  To break the notational asymmetry between the first two
contributions and the various intersections I will also refer to all of these
contributions by their _order_, starting with the zeroth-order contribution from
the baseline.  This ordering will also be consistent with the more formal
treatment in [Section 3.4](#sec:tensor).

<!--html_preserve-->
<center>
<table style="width:60%; text-align: center;">
  <tr style="background-color:#F9F9F9;">
    <th>Common Name</th>
    <th>Overall Order</th>
    <th>Number of Factors</th>
    <th>Levels within Each Factor</th>
    <th>Factor Notation</th>
  </tr>
  <tr>
    <td>Baseline</td>
    <td>Zeroth</td>
    <td>$${ N_{F} \choose 0 } = 1$$</td>
    <td>$$1$$</td>
    <td>$$\theta$$</td>
  </tr>
  <tr>
    <td>Main Contribution</td>
    <td>First</td>
    <td>$${ N_{F} \choose 1 } = N_{F}$$</td>
    <td>$$L_{f}$$</td>
    <td>$$\delta^{f}_{l}$$</td>
  </tr>
  <tr>
    <td>First-Order Interaction</td>
    <td>Second</td>
    <td>$${ N_{F} \choose 2 }$$</td>
    <td>$$L_{f_{1}} \cdot L_{f_{2}}$$</td>
    <td>$$\delta^{f_{1}, f_{2}}_{l_{1}, l_{2}}$$</td>
  </tr>
  <tr>
    <td>R-th Order Interaction</td>
    <td>(R + 1)st</td>
    <td>$${ N_{F} \choose R + 1 }$$</td>
    <td>$$L_{f_{1}} \cdot \ldots \cdot L_{f_{R}}$$</td>
    <td>$$\delta^{f_{1}, \ldots, f_{R}}_{l_{1}, \ldots, l_{R}}$$</td>
  </tr>
</table>
</center>
<!--/html_preserve-->

The interpretational subtleties of the residual construction are especially
important here.  Again because all of the contributions are integrated together
when generating data they are meaningful only in relation to each other.  In
order to avoid misleading interpretations it's best to always explicitly specify
the levels of each context and the assumptions about those contributions.

For example the main contributions are often interpreted as the behavior within
each factor level; in our card example we might talk about the isolated
influence from color on the behavior of the cards.  There are no cards, however,
that are characterized by _only_ color.  The contributions from the color and
symbol levels always accompany each other, not to mention the corresponding
intersections.  In order to isolate an independent color contribution we'd have
to consider an artificial circumstance where baseline contribution, the main
symbol contributions, and all of the intersection contributions vanish,
$$
\begin{align*}
\theta &= \delta^{f_{2}}_{l_{2}} = \delta^{f_{1}, f_{2}}_{l_{1}, l_{2}} = 0
\\
\theta^{f_{1}, f_{2}}_{l_{1}, l_{2}}
&= 0 + \delta^{f_{1}}_{l_{1}} + 0 + 0
= \delta^{f_{1}}_{l_{1}}.
\end{align*}
$$

If the artificiality of this
construction is taken for granted then it can lead to far more misunderstanding
than insight.

## Residual Hierarchies

Once we've decomposed the full interaction factor into a residual sequence
we can build a multifactor compatible hierarchical model by assigning
independent hierarchies to each contributing factor,
$$
\begin{align*}
\theta^{f_{1}, f_{2}}_{l_{1}, l_{2}}
&= \theta
+ \delta^{f_{1}}_{l_{1}} + \delta^{f_{2}}_{l_{2}}
+ \delta^{f_{1}, f_{2}}_{l_{1}, l_{2}}
\\
\delta^{f_{1}, f_{2}}_{l_{1}, l_{2}} &\sim \pi( \phi^{f_{1}, f_{2}} )
\\
\delta^{f_{1}}_{l_{1}} &\sim \pi( \phi^{f_{1}} )
\\
\delta^{f_{2}}_{l_{2}} &\sim \pi( \phi^{f_{2}} ).
\end{align*}
$$

The advantage of this construction over building a hierarchy over the main
interaction factor levels directly is that we have much more flexibility in the
prior modeling.

In particular if the higher-order interactions grow weaker, and the behavior of
each context is dominated by the leading-order contributions, then we can use
narrower priors on the higher-order population parameters to provide stronger
regularization.  This is especially useful given that the higher-order
interaction factor levels will be more sparsely occupied and less constrained by
the observed likelihood function than the lower-order terms.

At the same time if the significance of the contributions does decay with order
then at some point the higher-order contributions can be neglected without
really affecting the quality of our inferences.  Although dropping higher-order
contributions technically results in hierarchical models that are not _exactly_
compatible with the overlapping exchangeability of the individual factors, we
may not be able to resolve those incompatibilities without the very precise
inferences afforded by massive data sets.

In fact the residual construction provides a natural scaffolding for expanding
our hierarchical models with a sequence of _truncated_ models that capture more
and more delicate features of the interacting factors.  We start with a
zeroth-order model where all of the intersection levels behave the same,
$$
\delta^{f_{1}, \ldots, f_{F}}_{l_{1}, \ldots, l_{F}} \approx \theta.
$$
Once we fit this initial model we can look for indications of heterogeneity
across the factor levels with carefully designed posterior retrodictive checks.
If these checks indicate that excess heterogeneity is important then we might
add the first-order residuals,
$$
\delta^{f_{1}, \ldots, f_{F}}_{l_{1}, \ldots, l_{F}}
\approx \theta + \sum_{f = 1}^{F} \delta^{f}_{l_{f}},
$$
and then check for excess heterogeneity within the first-order intersection
groups.  If we continue to see excesses then we can add the first-order
intersections into the model,
$$
\delta^{f_{1}, \ldots, f_{F}}_{l_{1}, \ldots, l_{F}}
\approx
\theta
+ \sum_{f = 1}^{F} \delta^{f}_{l_{f}}
+ \sum_{f_{1} = 1}^{F} \sum_{f_{1} = f_{2} + 1}^{F}
+ \delta^{f_{1}, f_{2}}_{l_{f_{1}}, f_{2}}.
$$

In practice expansion based on posterior retrodictive checks alone is limited
by our ability to design a summary statistic that is directly sensitive to the
potential heterogeneity.  This is especially true in complex models where the
heterogeneity is only one of many different, varying contributions to the data
generating process.  The residual scaffolding, however, can still be useful even
without sensitive posterior retrodictive checks.  Instead of terminating when
the posterior retrodictive checks show no deviant behavior we can terminate when
the posterior inferences for the most recent, highest-order contribution are
consistent with zero.

By following the natural order of the residuals we model only as much
heterogeneity as is supported by our observations, avoiding degenerate
inferences from over-parameterized models without sacrificing explanatory power
within the scope of those observations.  Of course if that scope changes then
the validity of a truncated model will also, in general, change.  In particular
a truncated model that is sufficient for a small data set is unlikely to remain
sufficient when we consider larger data sets where we can resolve more and more
subtle behaviors that often manifest only in the higher-order interaction
contributions.

## Extra Credit: Getting Tensor {#sec:tensor}

The residual expansion that we constructed somewhat heuristically above can be
formalized more rigorously using the mathematics of _tensor algebra_.

Consider two vectors: $\mathbf{a}$ containing $N_{\mathbf{a}}$ elements and
$\mathbf{b}$ containing $N_{\mathbf{b}}$ elements.  There are two natural ways
to combine these vectors into new objects.

Firstly the _direct sum_ $\mathbf{a} \oplus \mathbf{b}$ is the vector with
$N_{\mathbf{a}} + N_{\mathbf{b}}$ elements obtained by concatenating the
elements of the two vectors together.

<center>
<br>
```{r, out.width = "33%", echo=FALSE}
knitr::include_graphics("figures/direct_sum/direct_sum.png")
```
<br><br>
</center>

Given $I$ vectors $\mathbf{f}_{i}$ we can apply the direct sum recursively,
concatenating all of the vectors together to construct the total direct sum
$\oplus_{i = 1}^{I} \mathbf{f}_{i}$ with $\sum_{i = 1}^{I} N_{\mathbf{f}_{i}}$
total elements.

Secondly the _tensor product_ $\mathbf{a} \otimes \mathbf{b}$ is a collection of
$N_{\mathbf{a}} \cdot N_{\mathbf{b}}$ elements defined by replicating the
_entire vector $\mathbf{b}$_ for every element of $\mathbf{a}$, or equivalently
replicating the entire vector $\mathbf{a}$ for every element of $\mathbf{b}$.
Individual elements of the tensor product can be defined by picking one element
of $\mathbf{a}$ and then an element of the associated copy of $\mathbf{b}$, or
vice versa.  In other words every element $\mathbf{a} \otimes \mathbf{b}$ can be
defined by an ordered pair $(a, b)$, where $a$ is an element of $\mathbf{a}$ and
$b$ is an element of $\mathbf{b}$.

<center>
<br>
```{r, out.width = "50%", echo=FALSE}
knitr::include_graphics("figures/tensor_product/tensor_product.png")
```
<br><br>
</center>

The component vectors are denoted _rank one tensors_ and their tensor product a
_rank two tensor_.

Given $I$ vectors $\mathbf{f}_{i}$ we can apply the tensor product recursively
to construct a rank $I$ tensor $\oplus_{i = 1}^{I} \mathbf{f}_{i}$ with
$\prod_{i = 1}^{I} N_{\mathbf{f}_{i}}$ total elements.  This then allows us to
define the tensor product of a rank $R$ tensor with $N_{1}$ elements and a rank
$S$ tensor with $N_{2}$ elements as a rank $R + S$ tensor with
$N_{1} \cdot N_{2}$ elements.

The tensor product of $I$ vectors defines an $I$-dimensional, or rank $I$,
_multidimensional array_.  Each element is identified with $I$ indices, where
the $i$th index identifies which element of the $i$th component vector
contributes to the tensor element.

The direct sum and tensor product play nicely with each other, generating an
_algebra_ with many of the properties familiar to the integers and the real
numbers.  For example if $\mathbf{1}$ denotes a constant vector then we can
expand products of sums,
$$
\begin{align*}
(\mathbf{1} \oplus \mathbf{a} \oplus \mathbf{b})^{2}
&=
(\mathbf{1} \oplus \mathbf{a} \oplus \mathbf{b})
\otimes
(\mathbf{1} \oplus \mathbf{a} \oplus \mathbf{b})
\\
&=
\;\;\;\; (\mathbf{1} \otimes \mathbf{1})
\oplus (\mathbf{1} \otimes \mathbf{a})
\oplus (\mathbf{1} \otimes \mathbf{b})
\\
&\quad
\oplus \, (\mathbf{a} \otimes \mathbf{1})
\oplus (\mathbf{a} \otimes \mathbf{a})
\oplus (\mathbf{a} \otimes \mathbf{b})
\\
&\quad
\oplus \, (\mathbf{b} \otimes \mathbf{1})
\oplus (\mathbf{b} \otimes \mathbf{a})
\oplus (\mathbf{b} \otimes \mathbf{b}).
\end{align*}
$$

Now something interesting happens if assume that the quadratic terms in
$\mathbf{a}$ and $\mathbf{b}$ vanish,
$$
\mathbf{a} \otimes \mathbf{a} = \mathbf{b} \otimes \mathbf{b} = 0,
$$
that the order of the direct sums doesn't matter,
$$
\mathbf{a} \oplus \mathbf{b} = \mathbf{b} \oplus \mathbf{a},
$$
and finally that the order of the tensor products doesn't matter,
$$
\mathbf{a} \otimes \mathbf{b} = \mathbf{b} \otimes \mathbf{a}.
$$
In this case the expanded product reduces to
$$
\begin{align*}
(\mathbf{1} \oplus \mathbf{a} \oplus \mathbf{b})^{2}
&=
\quad (\mathbf{1} \otimes \mathbf{1})
\\
& \quad
\oplus (\mathbf{a} \otimes \mathbf{1}) \oplus (\mathbf{1} \otimes \mathbf{b})
\\
& \quad
\oplus (\mathbf{a} \otimes \mathbf{b})
\end{align*}
$$
which has the exact same form as residual expansion that we derived in
[Section 3.2](#sec:residual_expansion)! 

In particular we can associate $\mathbf{a}$ and $\mathbf{b}$ with two factors,
$\mathbf{1} \otimes \mathbf{1}$ the rank zero baseline contribution,
$\mathbf{a} \otimes \mathbf{1}$ and $\mathbf{1} \otimes \mathbf{b}$ the rank one
main contributions, and $\mathbf{a} \otimes \mathbf{b}$ the rank two interaction
contribution.  Truncating the residual expansion then corresponds to a
_low rank approximation_ of the tensor product
$(\mathbf{1} \oplus \mathbf{a} \oplus \mathbf{b})^{2}$.

For example given the factor $\mathbf{a}$ with four levels and the factor
$\mathbf{b}$ with three levels we can expand
$$
( \mathbf{1} \otimes \mathbf{a} \otimes \mathbf{b})^{2}
$$
into a series of contributions with progressively increasing rank.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/rank2_tensor_decomp/rank2_tensor_decomp.png")
```
<br><br>
</center>

Given three factors -- $\mathbf{a}$ with four levels, $\mathbf{b}$ with three
levels, and $\mathbf{c}$ with five levels -- the product
$$
( \mathbf{1} \otimes \mathbf{a} \otimes \mathbf{b} \otimes \mathbf{c})^{3}
$$
admits a similar decomposition.

<center>
<br>
```{r, out.width = "100%", echo=FALSE}
knitr::include_graphics("figures/rank3_tensor_decomp/rank3_tensor_decomp.png")
```
<br><br>
</center>

In general given $I$ factors we can use this particular tensor algebra to
_systematically_ generate and organize all of the terms in the residual
expansion, including all of the higher-order interaction factors, by expanding
$$
\big( \mathbf{1} \oplus ( \oplus_{i = 1}^{I} \mathbf{f}_{i} ) \big)^{I},
$$
dropping all terms with more than one factor of any of the $\mathbf{f}_{i}$,
and then combining any tensor products that are equivalent up to permutations.
Although this may seem excessively formal in the low rank examples that we've
considered so far, it can be helpful when trying to reason about or even
automatically implement much higher rank systems.

## Residual Degeneracies

As useful as the residual expansion can be in structuring heterogeneity
and motivating principled model expansion, not to mention facilitating prior
modeling within each model iteration, the approach does introduce some
complications.  In particular if we don't observe enough contexts then our
likelihood functions may not be able to identify the different residual
contributions from each other.

Recall that we can interpret the contributions at any order as coming from an
appropriate factor.  For example the baseline contribution is given by a factor
with just one level, the main contributions are given by the main factors, and
the first-order interaction contribution is given by the interaction factors
formed by intersecting the levels from each pair of main factors.  How many
observations are associated with each level, or the _occupancy_, provides
critical information about how degenerate our inferences of those levels will
be with the levels of lower-order factors.

Those levels that have no occupancy at all are of particular interest.  Let's
define a _factor configuration_ as a binary classification of which levels have
zero occupancy and which levels have non-zero occupancy.  For first order
interactions we can readily communicate this configuration with a table or
lattice plot.

<center>
<br>
```{r, out.width = "50%", echo=FALSE}
knitr::include_graphics("figures/context_to_inter/context_to_inter.png")
```
<br><br>
</center>

Careful analysis of these configurations can alert us to degeneracies between
the different residual contributions.  For example consider a first-order
factor where only one level is observed.

<center>
<br>
```{r, out.width = "50%", echo=FALSE}
knitr::include_graphics("figures/context_to_inter_degen1/context_to_inter_degen1.png")
```
<br><br>
</center>

Because only one level is observed we can shift a constant between the baseline
term and this main factor contribution without affecting the reconstructed
behavior,
$$
\begin{align*}
\theta^{f_{1}, f_{2}}_{l_{1}, l_{2}}
&=
\theta + \delta^{f_{1}}_{l_{1}}
\\
&=
\big( \theta + \alpha \big) + \big( \delta^{f_{1}}_{l_{1}} - \alpha \big),
\end{align*}
$$
resulting in a non-identified likelihood function.  We need to observe _some_
heterogeneity in order to distinguish the two contributions!

Similarly consider two factors but observe only one interaction level associated
with two factor levels.

<center>
<br>
```{r, out.width = "50%", echo=FALSE}
knitr::include_graphics("figures/context_to_inter_degen2/context_to_inter_degen2.png")
```
<br><br>
</center>

In this case we can shift a constant between the two main factor contributions
and the corresponding interaction contributions without affecting the
reconstructed behavior,
$$
\begin{align*}
\theta^{f_{1}, f_{2}}_{2, 2}
&=
\theta
+ \delta^{f_{1}}_{2} + \delta^{f_{2}}_{2}
+ \delta^{f_{1}, f_{2}}_{2, 2}
\\
&=
\theta
+ \big( \delta^{f_{1}}_{2} - \alpha \big)
+ \big( \delta^{f_{2}}_{2} - \beta \big)
+ \big( \delta^{f_{1}, f_{2}}_{2, 2} + \alpha + \beta \big),
\end{align*}
$$
resulting in yet another non-identifiable likelihood function.

These non-identified configurations lead to degenerate likelihood functions no
matter how much data we replicate with that particular factor configuration.
Prior models can help regularize the resulting posterior inferences, but ideally
we would observe a sufficient diversity of contexts so that the likelihood
function could do its fair share.

The study and design of factor configurations that allow higher-order
interactions to be distinguished from the lower-order contributions is a key
objective of _experimental design_ in classical statistics [@BoxEtAl:2005].
In particular sophisticated combinatoric methods motivate particular factor
configurations, or designs, such as Latin hypercubes that are capable of
identifying certain interaction terms with as few observed contexts as possible.

While these methods are intended to help in the design controlled experiments,
they can also be useful for identifying the degeneracies inherent to an
accidental or unintended factor configuration, for example one that arises when
measurements are subjected to heavy selection bias.  This information then
informs what orders of residuals might be feasible as well as on which
contributions we might need to focus elicitation of domain expertise for
more informative prior models.

## The Limitations of Overlapping Multifactor Models

Ultimately the residual decomposition is just a way of organizing heterogeneity
across the overlapping levels of the component factors.  As with any
exchangeable model this organizations allows us to learn _how_ behavior varies
across the factor levels and their intersections, but it doesn't tell us _why_
the behavior varies.  When we assume that these exact variations extrapolate to
external circumstances we are implicitly making assumptions not just about the
multifactor model itself but also the generative process from which those
heterogeneities arise, and hence the _interpretation_ of the multifactor model.

This is especially important when the interpretation of the factor levels, or
their assignments, is ambiguous.  For example because many common demographic
factors like ethnicity and race are socially constructed, their level
assignments can differ significantly when self-identified by the individuals
themselves or externally identified by researchers.  Even if substantial
heterogeneity manifests across the assigned levels we will have trouble
determining how that heterogeneity generalizes if we don't understand how those
levels were assigned, and hence the precise interpretation of the factors.

Moreveor how well a decomposition of heterogeneity across the factor levels
and their intersections captures the behavior of any latent generative process
depends on exactly which factors, and which levels within those factors, are
considered.  If the factor levels poorly correlate with the generative process
then even multifactor models with higher-order interactions will resolve only a
partial picture of that process; the heterogeneity that manifests across those
levels and their intersections will provide only limited information that, at
best, awkwardly generalizes to external circumstances.  Indeed the less
sensitive the levels are to the generative structure, the more prone the
resulting multifactor models will be to contorting to accidental patterns in the
observations that do happen to align with the factors.

For example consider the case where we're using a multifactor model to capture
systematic behavior inherent to a particular measurement procedure, as opposed
to behavior that manifests from the latent phenomena being observed.  If the
factors aren't rich enough to fully represent those systematic behaviors then
the phenomenological part of the model may attempt to compensate.  The resulting
inferences of the phenomenological behavior will then be corrupted by this
contortion and poorly generalize to circumstances where the latent phenomena is
observed differently.

Similarly consider the case where our measurements probe some phenomena about
which we don't yet know enough to build a generative model.  In this case we
might use a multifactor model as an initial heuristic model to learn about the
broad behavior of that latent phenomena.  Again if we don't include enough
relevant factors then our inferences can be erratic, in the best case highly
uncertain and in the worst case misleading as the rigid factors adapt to
only certain projections of the latent phenomenological behavior of interest.
When trying to increases sales, for example, a multifactor model based on
demographic factors will be of limited use if patterns in purchasing behavior
do not manifest as a strong heterogeneity within demographic levels and their
lower-order interactions.

At the same time the factor levels that are actually observed can be just as
critical.  When observations exhaust all of the input factor levels we know that
our data are sensitive to the full range of possible behaviors that the
multifactor model can accommodate.  If many levels are unobserved, however, then
the resulting multifactor model will not take full advantage of the given
factors!

For example classical experimental design is often focused on probing the
behavior of some system only around some operational baseline.  In particular
only a few factors levels that most strongly associated with the baseline levels
might be included.

<center>
<br>
```{r, out.width = "75%", echo=FALSE}
knitr::include_graphics("figures/context_to_inter_narrow/context_to_inter_narrow.png")
```
<br><br>
</center>

Although we assume that the heterogeneity across the levels is exchangeable,
the design for which levels are observed is very much not exchangeable here!
Because of this limitation the resulting multifactor model will be sensitive
only to behavior around that chosen baseline.  When working with only partially
observed factors it's critical to investigate the behavior near the boundary
levels for any indications of trends that might persist beyond, for example
trends that peak around the "X" in the above figure.  In some cases expanding
factor designs to include more levels can be more useful than adding new
factors!

As critical as the choice of main factors, their observed levels, and their
interpretations is, we do not always have the luxury of that choice in practice.
In many cases the available factors are determined not by careful statistical
design but rather by external conventions or even alternative priorities such as
privacy.  For example when working with survey data we are typically limited to
common demographic factors that may correlate poorly with the behaviors in which
we're interested.  When we aren't able to design relevant factors we have to be
especially mindful of the limitations of overlapping multifactor models and
their resulting inferences.

When the main factors are well chosen, and the behavior of the system being
observed manifests in largely independent variation across the each factor, then
the interaction factors tend to be less important and can often be ignored
without a substantial loss of exploratory power.  If the main factors are not
quite as well chosen, however, then those behaviors often manifest most
strongly in the interaction levels.  Indeed the more complex the behavior the
higher the order of the interaction in which it will tend to manifest.

The importance of interactions in understanding sophisticated systems is well
known in many fields.  For instance the framework of _intersectionality_
[@Crenshaw:1989] emphasizes the important societal, cultural, and political
consequences that vary across the intersections of common demographic features.
The experience of a Black woman, for example, cannot in most circumstances be
accurately characterized solely by the experiences common to all women and the
experiences common to all Black people.  Ignoring this interaction then results
in not just poor inferences but also ineffectual policy informed by those
inferences.  Of course the importance of these interactions is further
complicated by the interpretation of race as discussed above!

In order to ensure robust inferences we cannot take for granted the dominance of
the main factors, and the negligibility of the interaction factors.  While
finite measurements may not be able to resolve any heterogeneity in the
interactions factors, especially the higher-order interaction factors, we have
to explicitly verify that this is the case in any given analysis with, for
example, posterior inferences or posterior retrodictive checks.

Ultimately the choice of both main and interaction factors is critical to the
utility of a multifactor model.  The more each factor is sensitive to the
relevant behavior the more generative consequences the resulting multifactor
model will be able to represent.  Similarly the more precisely we can interpret
each factor the more we can understand those generative consequences and the
better we will be able to determine when those consequences generalize.

# Experiments

To reinforce these concepts let's put them to work in some demonstrative
examples.  In this section we'll review implementations of single factor,
nested multifactor, and overlapping multifactor models in Stan and some basic
workflow principles.

We begin by setting up our local `R` environment.

```{r, warning=FALSE, message=FALSE}
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
parallel:::setDefaultClusterOptions(setup_strategy = "sequential")

util <- new.env()
source('stan_utility.R', local=util)

c_light <- c("#DCBCBC")
c_light_highlight <- c("#C79999")
c_mid <- c("#B97C7C")
c_mid_highlight <- c("#A25050")
c_dark <- c("#8F2727")
c_dark_highlight <- c("#7C0000")

c_light_trans <- c("#DCBCBC80")
c_dark_trans <- c("#8F272780")
c_green_trans <- c("#00FF0080")

par(family="CMU Serif", las=1, bty="l", cex.axis=1, cex.lab=1, cex.main=1,
    xaxs="i", yaxs="i", mar = c(5, 5, 3, 5))
   
set.seed(9958284)
```

## Single Factor Models in Action

First let's read in our data and take a look at its contents.

```{r}
data <- read_rdump("data/single_factor1.data.R")

names(data)
```

The data `y` contain `N = 4050` independent, one-dimensional, and real-valued
values `y` each generated with a known measurement variability `sigma`.

These observations are reasonably uniformly distribution across `K = 81`
individual contexts.  The variable `obs_to_context` identifies to which context
each observation is associated.

```{r}

hist(data$obs_to_context, breaks=seq(0.5, data$K + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$K + 0.5), xlab="Context",
     ylim=c(0, 80), ylab="Context Observations")
```

Our lone factor spans `N_factor_levels = 9` levels, each of which contains
`9` indiviual contexts.  The variable `context_to_level` identifies to which
factor level each individual context is associated.

```{r}
hist(data$context_to_level, breaks=seq(0.5, data$N_factor_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor_levels + 0.5), xlab="Level",
     ylim=c(0, 10), ylab="Level Occupancies")
```

Composing `obs_to_context` and `context_to_level` identifies to which factor
level each observation is associated, allowing us to for example count how many
observations inform the behavior in each level.  Because the observations within
context and contexts within levels are reasonably uniformly distributed so too
are the observations within each level.

```{r}
hist(data$context_to_level[data$obs_to_context],
     breaks=seq(0.5, data$N_factor_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor_levels + 0.5), xlab="Level",
     ylim=c(0, 500), ylab="Level Observations")
```

Implementing a hierarchical model capturing both the marginal and conditional
exchangeability induced by the factor is pretty straightforward in Stan.  Here
we use a monolithically centered parameterization.

```{r}
writeLines(readLines("stan_programs/marginal_conditional_cp.stan"))
```

Given the program Stan can do its Hamiltonian thing.

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/marginal_conditional_cp.stan',
            data=data, seed=4838282, refresh=1000)
```

No diagnostics indications of problems provides some confidence that we can
trust the fit.

```{r}
util$check_all_diagnostics(fit)
```

To visualize the posterior inferences for the marginal heterogeneity we plot
the level parameters together with the population location for comparison, and
then the population scale on the side.  We infer significant variation across
the factor levels.

```{r, fig.height=4}
samples <- extract(fit)

layout(matrix(c(1, 1, 2), nrow=1))

L <- data$N_factor_levels
idx <- rep(1:(L + 1), each=2)
x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:L, function(l)
                    quantile(samples$factor_theta[,l], probs=probs))
cred <- cbind(cred, quantile(samples$factor_mu, probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

par(mar=c(5, 5, 3, 1))
plot(1, type="n", main="Marginal Heterogeneity",
     xlim=c(0.5, L + 1.5), xlab="", xaxt="n",
     ylim=c(min(pad_cred[1,]), max(pad_cred[9,])), ylab="Marginal Posterior")
abline(v=L+0.5, col="gray80", lwd=2, lty=3)

polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = c_light, border = NA)
polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = c_mid, border = NA)
polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = c_mid_highlight, border = NA)
for (l in 1:(L + 1))
  lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

axis(1, at=1:(L + 1),
     labels=c(sapply(1:L, function(l) paste("l", l, sep="")), "mu"))

par(mar=c(5, 1, 3, 1))
u <- 1.25 * max(samples$factor_tau)
hist(samples$factor_tau, breaks=seq(0, u, u / 50), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
```

In order to visualize the conditional heterogeneity we have to repeat this for
the hierarchical models within each of the nine levels. The variation is
consistently strong across all of the levels.

```{r, fig.height=4}
for (l in 1:L) {
  layout(matrix(c(1, 1, 2), nrow=1))

  context_idx <- which(data$context_to_level == l)
  K <- length(context_idx)
  idx <- rep(1:(K + 1), each=2)
  x <- sapply(1:length(idx), function(k) if(k %% 2 == 0) idx[k] + 0.5 else idx[k] - 0.5)

  probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
  cred <- sapply(context_idx, function(k)
                      quantile(samples$context_theta[,k], probs=probs))
  cred <- cbind(cred, quantile(samples$factor_theta[,l], probs=probs))
  pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

  par(mar=c(5, 5, 3, 1))
  plot(1, type="n", main=paste("Conditional Heterogeneity Within Level", l),
       xlim=c(0.5, K + 1.5), xlab="", xaxt="n",
       ylim=c(min(pad_cred[1,]), max(pad_cred[9,])), ylab="Marginal Posterior")
  abline(v=L+0.5, col="gray80", lwd=2, lty=3)

  polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
          col = c_light, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
          col = c_light_highlight, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
          col = c_mid, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
          col = c_mid_highlight, border = NA)
  for (k in 1:(K + 1))
    lines(x[(2*k-1):(2*k)], pad_cred[5,(2*k-1):(2*k)], col=c_dark, lwd=2)


  axis(1, at=1:(K + 1),
       c(sapply(context_idx, function(k) paste("c", k, sep="")), paste("l", l, sep="")))

  par(mar=c(5, 1, 3, 1))
  u <- 1.25 * max(samples$residual_tau[,l])
  hist(samples$residual_tau[,l], breaks=seq(0, u, u / 50), main="",
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
}
```

The same model can also be implemented with a non-centered parameterization with
respect to the location parameters, resulting in a natural a residual
interpretation.  Note that the program is still centered with respect to the
scale parameters.

```{r}
writeLines(readLines("stan_programs/marginal_conditional_residual_cp.stan"))
```

We run.

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/marginal_conditional_residual_cp.stan',
            data=data, seed=4838282, refresh=1000)
```

No indications of fitting problems.

```{r}
util$check_all_diagnostics(fit)
```

This new parameterization suggests a different visualization of our posterior
inferences.  We first show the marginal posterior for the baseline parameter.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1), mar=c(5, 1, 3, 1))

hist(samples$baseline, breaks=seq(0, 15, 0.1), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 11), xlab="Baseline", yaxt='n', ylab="")
```

We can then visualize the marginal residuals common to each factor level.  In
this case I also show lines for 0, plus twice the scale mean, and minus twice
the scale mean to make it easier to compare the two plots.

```{r, fig.height=4}
layout(matrix(c(1, 1, 2), nrow=1))

L <- data$N_factor_levels
idx <- rep(1:L, each=2)
x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:L, function(l)
  quantile(samples$delta_factor[,l], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

mean_tau <- mean(samples$delta_factor_tau)

lb <- min(c(-2.25 * mean_tau, cred[1,]))
ub <- max(c(2.25 * mean_tau,  cred[9,]))

par(mar=c(5, 5, 3, 1))
plot(1, type="n", main="Marginal Heterogeneity",
     xlim=c(0.5, L + 0.5), xlab="", xaxt="n",
     ylim=c(lb, ub), ylab="Marginal Posterior")

lines(c(0.5, L + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
lines(c(0.5, L + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
lines(c(0.5, L + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = c_light, border = NA)
polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = c_mid, border = NA)
polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = c_mid_highlight, border = NA)
for (l in 1:L)
  lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

axis(1, at=1:L, labels=sapply(1:L, function(l) paste("l", l, sep="")))

par(mar=c(5, 1, 3, 1))
u <- 1.25 * max(samples$delta_factor_tau)
hist(samples$delta_factor_tau, breaks=seq(0, u, u / 50), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
abline(v=mean_tau, col="gray80", lwd=2, lty=3)
```

The conditional residuals for the individual contexts within each level are
visualized similarly.

```{r, fig.height=4}
for (l in 1:L) {
  layout(matrix(c(1, 1, 2), nrow=1))

  context_idx <- which(data$context_to_level == l)
  K <- length(context_idx)
  idx <- rep(1:K, each=2)
  x <- sapply(1:length(idx), function(k) if(k %% 2 == 0) idx[k] + 0.5 else idx[k] - 0.5)

  probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
  cred <- sapply(context_idx, function(k)
    quantile(samples$delta_context[,k], probs=probs))
  pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

  mean_tau <- mean(samples$delta_context_tau[,l])

  lb <- min(c(-2.25 * mean_tau, cred[1,]))
  ub <- max(c(2.25 * mean_tau,  cred[9,]))

  par(mar=c(5, 5, 3, 1))
  plot(1, type="n", main=paste("Conditional Heterogeneity Within Level", l),
       xlim=c(0.5, K + 0.5), xlab="", xaxt="n",
       ylim=c(lb, ub), ylab="Marginal Posterior")

  lines(c(0.5, K + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
  lines(c(0.5, K + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
  lines(c(0.5, K + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

  polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
          col = c_light, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
          col = c_light_highlight, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
          col = c_mid, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
          col = c_mid_highlight, border = NA)
  for (k in 1:K)
    lines(x[(2*k-1):(2*k)], pad_cred[5,(2*k-1):(2*k)], col=c_dark, lwd=2)

  axis(1, at=1:(K + 1),
       c(sapply(context_idx, function(k) paste("c", k, sep="")), paste("l", l, sep="")))

  par(mar=c(5, 1, 3, 1))
  u <- 1.25 * max(samples$delta_context_tau[,l])
  hist(samples$delta_context_tau[,l], breaks=seq(0, u, u / 50), main="",
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
  abline(v=mean_tau, col="gray80", lwd=2, lty=3)
}
```

Riding high on statistics let's consider a different observation of the same
system.

```{r}
data <- read_rdump("data/single_factor2.data.R")
```

Here we have only `N = 810` total observations distributed across the same
`K = 81` individual contexts.

```{r}
par(mfrow=c(1, 1), mar=c(5, 5, 3, 5))

hist(data$obs_to_context, breaks=seq(0.5, data$K + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$K + 0.5), xlab="Context",
     ylim=c(0, 25), ylab="Context Observations")
```

The level occupancies are no longer exactly uniform as well.

```{r}
hist(data$context_to_level, breaks=seq(0.5, data$N_factor_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor_levels + 0.5), xlab="Level",
     ylim=c(0, 15), ylab="Level Occupancies")
```

Consequently the number of observations associated with each level are fewer and
more variable.

```{r}
hist(data$context_to_level[data$obs_to_context],
     breaks=seq(0.5, data$N_factor_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor_levels + 0.5), xlab="Level",
     ylim=c(0, 175), ylab="Level Observations")
```

How will our current Stan program fare?

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/marginal_conditional_residual_cp.stan',
            data=data, seed=4838282, refresh=1000)
```

Not well!

```{r}
util$check_all_diagnostics(fit)
```

Let's track down those divergences to see if we can find the problem.

```{r}
partition <- util$partition_div(fit)
div_samples <- partition[[1]]
nondiv_samples <- partition[[2]]
```

The marginal level parameters exhibit a mild funnel geometry.

```{r}
par(mfrow=c(3, 3))
par(mar=c(5, 5, 3, 1))

for (l in 1:9) {
  name_x <- paste("delta_factor[", l, "]", sep='')
  name_y <- "delta_factor_tau"

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=paste("l =", l),
       xlab=name_x, xlim=c(-6, 6),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-1, 2))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

The context parameters, however, show much stronger funnels.  The concentration
of divergences in the neck of some of the funnels strongly indicates that we
need to fully non-center these parameters.

```{r, fig.height=2}
par(mfrow=c(1, 4))

for (k in 1:81) {
  name_x <- paste("delta_context[", k, "]", sep='')
  name_y <- paste("delta_context_tau[", data$context_to_level[k], "]", sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=paste("k =", k),
       xlab=name_x, xlim=c(-15, 15),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-5, 3))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

Instead of writing a Stan program for each possible parameterization let's be a
little more foresightful and write one Stan program with a configurable
parameterization.

```{r}
writeLines(readLines("stan_programs/marginal_conditional_residual_mixed.stan"))
```

To start we fully non-center all of the parameters.

```{r}
data$context_cp_idx <- vector()
data$K_cp <- length(data$context_cp_idx)

data$context_ncp_idx <- setdiff(1:data$K, data$context_cp_idx)
data$K_ncp <- length(data$context_ncp_idx)

data$factor_cp_idx <- vector()
data$L_cp <- length(data$factor_cp_idx)

data$factor_ncp_idx <- setdiff(1:data$N_factor_levels, data$factor_cp_idx)
data$L_ncp <- length(data$factor_ncp_idx)
```

Hopeful, we try again.

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/marginal_conditional_residual_mixed.stan',
            data=data, seed=4838282, refresh=1000)
```

Fortunately the divergences have vanished and we no longer have any indication
that our Markov chains are not faithfully capturing our posterior inferences.

```{r}
util$check_all_diagnostics(fit)
```

Consequently we can proceed to visualize our results.  First the baseline.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1), mar=c(5, 1, 3, 1))

hist(samples$baseline, breaks=seq(0, 15, 0.1), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 11), xlab="Baseline", yaxt='n', ylab="")
```

Then the marginal residuals.

```{r, fig.height=4}
layout(matrix(c(1, 1, 2), nrow=1))

L <- data$N_factor_levels
idx <- rep(1:L, each=2)
x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:L, function(l)
  quantile(samples$delta_factor[,l], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

mean_tau <- mean(samples$delta_factor_tau)

lb <- min(c(-2.25 * mean_tau, cred[1,]))
ub <- max(c(2.25 * mean_tau,  cred[9,]))

par(mar=c(5, 5, 3, 1))
plot(1, type="n", main="Marginal Heterogeneity",
     xlim=c(0.5, L + 0.5), xlab="", xaxt="n",
     ylim=c(lb, ub), ylab="Marginal Posterior")

lines(c(0.5, L + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
lines(c(0.5, L + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
lines(c(0.5, L + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = c_light, border = NA)
polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = c_mid, border = NA)
polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = c_mid_highlight, border = NA)
for (l in 1:L)
  lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

axis(1, at=1:L, labels=sapply(1:L, function(l) paste("l", l, sep="")))

par(mar=c(5, 1, 3, 1))
u <- 1.25 * max(samples$delta_factor_tau)
hist(samples$delta_factor_tau, breaks=seq(0, u, u / 50), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
abline(v=mean_tau, col="gray80", lwd=2, lty=3)
```

Finally the conditional residuals.

```{r, fig.height=4}
for (l in 1:L) {
  layout(matrix(c(1, 1, 2), nrow=1))

  context_idx <- which(data$context_to_level == l)
  K <- length(context_idx)
  idx <- rep(1:K, each=2)
  x <- sapply(1:length(idx), function(k) if(k %% 2 == 0) idx[k] + 0.5 else idx[k] - 0.5)

  probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
  cred <- sapply(context_idx, function(k)
    quantile(samples$delta_context[,k], probs=probs))
  pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

  mean_tau <- mean(samples$delta_context_tau[,l])

  lb <- min(c(-2.25 * mean_tau, cred[1,]))
  ub <- max(c(2.25 * mean_tau,  cred[9,]))

  par(mar=c(5, 5, 3, 1))
  plot(1, type="n", main=paste("Conditional Heterogeneity Within Level", l),
       xlim=c(0.5, K + 0.5), xlab="", xaxt="n",
       ylim=c(lb, ub), ylab="Marginal Posterior")

  lines(c(0.5, K + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
  lines(c(0.5, K + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
  lines(c(0.5, K + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

  polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
          col = c_light, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
          col = c_light_highlight, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
          col = c_mid, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
          col = c_mid_highlight, border = NA)
  for (k in 1:K)
    lines(x[(2*k-1):(2*k)], pad_cred[5,(2*k-1):(2*k)], col=c_dark, lwd=2)

  axis(1, at=1:(K + 1),
       c(sapply(context_idx, function(k) paste("k", k, sep="")), paste("l", l, sep="")))

  par(mar=c(5, 1, 3, 1))
  u <- 1.25 * max(samples$delta_context_tau[,l])
  hist(samples$delta_context_tau[,l], breaks=seq(0, u, u / 50), main="",
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
  abline(v=mean_tau, col="gray80", lwd=2, lty=3)
}
```

As discussed in [Section 1.4](#sec:single_residual) the conditional
heterogeneity within each factor level is often not considered.  In this case
the levels themselves become the relevant contexts, and we need to provide a
mapping from observations to these new contexts.

```{r}
data$obs_to_level <- data$context_to_level[data$obs_to_context]
```

The corresponding Stan program doesn't require much more beyond excising the
conditional hierarchies.

```{r}
writeLines(readLines("stan_programs/marginal_residual_mixed.stan"))
```

Using the same non-centered parameterization set above we can immediately fit.

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/marginal_residual_mixed.stan',
            data=data, seed=4838282, refresh=1000)
```

With no indications of computational problems we can move onto investigating
the posterior.

```{r}
util$check_all_diagnostics(fit)
```

As with any residual model we start with the baseline parameter.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1), mar=c(5, 1, 3, 1))

hist(samples$baseline, breaks=seq(0, 15, 0.1), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 11), xlab="Baseline", yaxt='n', ylab="")
```

Then we can consider the level parameters that capture the marginal
heterogeneity.

```{r, fig.height=4}
layout(matrix(c(1, 1, 2), nrow=1))

L <- data$N_factor_levels
idx <- rep(1:L, each=2)
x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:L, function(l)
  quantile(samples$delta_factor[,l], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

mean_tau <- mean(samples$delta_factor_tau)

lb <- min(c(-2.25 * mean_tau, cred[1,]))
ub <- max(c(2.25 * mean_tau,  cred[9,]))

par(mar=c(5, 5, 3, 1))
plot(1, type="n", main="Marginal Heterogeneity",
     xlim=c(0.5, L + 0.5), xlab="", xaxt="n",
     ylim=c(lb, ub), ylab="Marginal Posterior")

lines(c(0.5, L + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
lines(c(0.5, L + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
lines(c(0.5, L + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = c_light, border = NA)
polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = c_mid, border = NA)
polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = c_mid_highlight, border = NA)
for (l in 1:L)
  lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

axis(1, at=1:L, labels=sapply(1:L, function(l) paste("l", l, sep="")))

par(mar=c(5, 1, 3, 1))
u <- 1.25 * max(samples$delta_factor_tau)
hist(samples$delta_factor_tau, breaks=seq(0, u, u / 50), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
abline(v=mean_tau, col="gray80", lwd=2, lty=3)
```

## Nested Multifactor Models in Action

Now let's advance to multiple factors with nested levels.

```{r}
data <- read_rdump("data/nested_multifactor.data.R")

names(data)
```

We have three three nested factors.  At the top Factor 3 has
`N_factor3_levels = 125` levels over which the `N = 750` observations are
relatively uniformly distributed.

```{r}
par(mar=c(5, 5, 3, 5))
par(mfrow=c(1, 1))

hist(data$obs_to_factor3, breaks=seq(0.5, data$N_factor3_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor3_levels + 0.5), xlab="Factor Three Levels",
     ylim=c(0, 12), ylab="Number of Observations")
```

The Factor 3 levels are then nested within `N_factor2_levels = 25` Factor 2
levels.

```{r}
hist(data$factor3_to_factor2, breaks=seq(0.5, data$N_factor2_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor2_levels + 0.5), xlab="Factor Two Levels",
     ylim=c(0, 12), ylab="Number of Factor Three Levels")
```

The observations associated with the Factor 2 levels are also relatively
uniform.

```{r}
hist(data$factor3_to_factor2[data$obs_to_factor3],
     breaks=seq(0.5, data$N_factor2_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor2_levels + 0.5), xlab="Factor Two Levels",
     ylim=c(0, 70), ylab="Number of Observations")
```

Finally the Factor 2 levels are nested within `N_factor1_levels = 5` Factor 1
levels.

```{r}
hist(data$factor2_to_factor1, breaks=seq(0.5, data$N_factor1_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor1_levels + 0.5), xlab="Factor One Levels",
     ylim=c(0, 8), ylab="Number of Factor Two Levels")
```

Each of these five Factor 1 levels is associated with many observations, which
also means that many more observations inform the behavior in those levels than
in the levels of the higher factors.

```{r}
hist(data$factor2_to_factor1[data$factor3_to_factor2[data$obs_to_factor3]],
     breaks=seq(0.5, data$N_factor1_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor1_levels + 0.5), xlab="Factor One Levels",
     ylim=c(0, 250), ylab="Number of Observations")
```

A general three factor nested model is similar to the full marginal conditional
model we build for a single factor, only with one more layers of nesting.
Knowing that we might need flexibility we start with a general implementation
where we can readily configure the parameterization of each hierarchical
parameter.

```{r}
writeLines(readLines("stan_programs/nested_factors_residual.stan"))
```

Let's first consider a fully non-centered parameterization.

```{r}
data$factor1_cp_idx <- vector()
data$L_factor1_cp <- length(data$factor1_cp_idx)

data$factor1_ncp_idx <- setdiff(1:data$N_factor1_levels, data$factor1_cp_idx)
data$L_factor1_ncp <- length(data$factor1_ncp_idx)

data$factor2_cp_idx <- vector()
data$L_factor2_cp <- length(data$factor2_cp_idx)

data$factor2_ncp_idx <- setdiff(1:data$N_factor2_levels, data$factor2_cp_idx)
data$L_factor2_ncp <- length(data$factor2_ncp_idx)

data$factor3_cp_idx <- vector()
data$L_factor3_cp <- length(data$factor3_cp_idx)

data$factor3_ncp_idx <- setdiff(1:data$N_factor3_levels, data$factor3_cp_idx)
data$L_factor3_ncp <- length(data$factor3_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/nested_factors_residual.stan',
            data=data, seed=4838282, refresh=1000)
```

Divergences: our sworn enemy.

```{r}
util$check_all_diagnostics(fit)
```

We can't let them escape.

```{r}
partition <- util$partition_div(fit)
div_samples <- partition[[1]]
nondiv_samples <- partition[[2]]
```

The population parameters for the first factor don't show any indication of
problematic geometry.

```{r}
par(mfrow=c(1, 1))

name_x <- "baseline"
name_y <- "delta_factor1_tau"

plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
     col=c_dark_trans, pch=16, main="Factor One Population",
     xlab=name_x, xlim=c(-8, 8),
     ylab=paste("log(", name_y, ")", sep=''), ylim=c(-7, 4))
points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
       col=c_green_trans, pch=16)
```

Nor do the population parameters for the hierarchical models nested within the
Factor 1 levels.  While there is some funnel-like behavior the divergences don't
indicate that the sampler is having any problem exploring it.

```{r, fig.height=2}
par(mar=c(5, 5, 4, 1))

par(mfrow=c(1, 4))

for (l in 1:data$N_factor1_levels) {
  if (l %in% data$factor1_cp_idx) {
    cp_idx <- which(l == data$factor1_cp_idx)
    name_x <- paste("delta_factor1_cp[", cp_idx, "]", sep='')
  } else {
    ncp_idx <- which(l == data$factor1_ncp_idx)
    name_x <- paste("delta_factor1_ncp[", ncp_idx, "]", sep='')
  }
  name_y <- paste("delta_factor2_tau[", l, "]", sep='')

  title <- paste("Factor Two Population\nNested Within\nFactor One Level", l);

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-8, 8),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-7, 4))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

The same is true for the population parameters for the hierarchical models
nested within the Factor 2 levels.

```{r, fig.height=2}
par(mfrow=c(1, 4))

for (l in 1:data$N_factor2_levels) {
  if (l %in% data$factor2_cp_idx) {
    cp_idx <- which(l == data$factor2_cp_idx)
    name_x <- paste("delta_factor2_cp[", cp_idx, "]", sep='')
  } else {
    ncp_idx <- which(l == data$factor2_ncp_idx)
    name_x <- paste("delta_factor2_ncp[", ncp_idx, "]", sep='')
  }
  name_y <- paste("delta_factor3_tau[", l, "]", sep='')

  title <- paste("Factor Three Population\nNested Within\nFactor Two Level", l);

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-8, 8),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-7, 4))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

We are then left to consider the correlation between the individual parameters
and the population scales.  Within the Factor 1 levels we see signs of an
inverted funnel, and the concentration of the divergences towards the tip of the
funnel suggests that these may be problematic to Stan's Hamiltonian Monte Carlo
sampler.

```{r, fig.height=2}
par(mar=c(5, 5, 3, 1))

par(mfrow=c(1, 4))

for (l in 1:data$N_factor1_levels) {
  if (l %in% data$factor1_cp_idx) {
    cp_idx <- which(l == data$factor1_cp_idx)
    name_x <- paste("delta_factor1_cp[", cp_idx, "]", sep='')
  } else {
    ncp_idx <- which(l == data$factor1_ncp_idx)
    name_x <- paste("delta_factor1_ncp[", ncp_idx, "]", sep='')
  }
  name_y <- "delta_factor1_tau"

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=paste("l1 =", l),
       xlab=name_x, xlim=c(-8, 8),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-7, 4))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

The individual parameters in the Factor 2 levels look somewhat suspicious, but
less so that the those nested in the Factor 1 levels.

```{r, fig.height=2}
for (l1 in 1:data$N_factor1_levels) {
  nested_factor2_idx <- which(data$factor2_to_factor1 == l1)

  par(mfrow=c(1, 4))
 
  for (l2 in nested_factor2_idx) {
    if (l2 %in% data$factor2_cp_idx) {
      cp_idx <- which(l2 == data$factor2_cp_idx)
      name_x <- paste("delta_factor2_cp[", cp_idx, "]", sep='')
    } else {
      ncp_idx <- which(l2 == data$factor2_ncp_idx)
      name_x <- paste("delta_factor2_ncp[", ncp_idx, "]", sep='')
    }
    name_y <- paste("delta_factor2_tau[", l1, "]", sep='')

    plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
         col=c_dark_trans, pch=16,
         main=paste("l1 = ", l1, ", l2 = ", l2, sep=""),
         xlab=name_x, xlim=c(-8, 8),
         ylab=paste("log(", name_y, ")", sep=''), ylim=c(-7, 4))
    points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
           col=c_green_trans, pch=16)
  }
}
```

Within the Factor 3 levels the individual parameters are even better behaved.

```{r, fig.height=2}
for (l2 in 1:data$N_factor2_levels) {
  nested_factor3_idx <- which(data$factor3_to_factor2 == l2)

  par(mfrow=c(1, 4))

  for (l3 in nested_factor3_idx) {
    if (l3 %in% data$factor3_cp_idx) {
      cp_idx <- which(l3 == data$factor3_cp_idx)
      name_x <- paste("delta_factor3_cp[", cp_idx, "]", sep='')
    } else {
      ncp_idx <- which(l3 == data$factor3_ncp_idx)
      name_x <- paste("delta_factor3_ncp[", ncp_idx, "]", sep='')
    }
    name_y <- paste("delta_factor3_tau[", l2, "]", sep='')
 
    plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
         col=c_dark_trans, pch=16,
         main=paste("l2 = ", l2, ", l3 = ", l3, sep=""),
         xlab=name_x, xlim=c(-8, 8),
         ylab=paste("log(", name_y, ")", sep=''), ylim=c(-7, 4))
    points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
           col=c_green_trans, pch=16)
  }
 
  mtext(paste("Factor Three Hierarchy Nested Within Factor Two Level", l2), outer = TRUE)
}
```

The fact that the lower parameters in the nested hierarchy behave more poorly
when non-centered is not surprising.  As we go deeper into the nested hierarchy
the data aggregates and more strongly informs the levels in the deeper factors
relative to the levels in the shallower factor levels.  In general the shallower
factor levels will be more well-suited to non-centered parameterizations while
the deeper factor levels will be more well-suited to centered parameterizations.

Let's start by centering just the individual parameters for the Factor 1 levels.

```{r}
data$factor1_cp_idx <- 1:data$N_factor1_levels
data$L_factor1_cp <- length(data$factor1_cp_idx)

data$factor1_ncp_idx <- setdiff(1:data$N_factor1_levels, data$factor1_cp_idx)
data$L_factor1_ncp <- length(data$factor1_ncp_idx)

data$factor2_cp_idx <- vector()
data$L_factor2_cp <- length(data$factor2_cp_idx)

data$factor2_ncp_idx <- setdiff(1:data$N_factor2_levels, data$factor2_cp_idx)
data$L_factor2_ncp <- length(data$factor2_ncp_idx)

data$factor3_cp_idx <- vector()
data$L_factor3_cp <- length(data$factor3_cp_idx)

data$factor3_ncp_idx <- setdiff(1:data$N_factor3_levels, data$factor3_cp_idx)
data$L_factor3_ncp <- length(data$factor3_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/nested_factors_residual.stan',
            data=data, seed=4838282, refresh=1000)
```

This seems to have done the trick as the divergences have vanished.

```{r}
util$check_all_diagnostics(fit)
```

Somewhat confident in the faithfulness of our computational fit we can start
examining our posterior inferences.  First we have the baseline parameter.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1), mar=c(5, 1, 3, 1))

hist(samples$baseline, breaks=seq(0, 15, 0.1), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 11), xlab="Baseline", yaxt='n', ylab="")
```

Then the Factor 1 hierarchy.

```{r, fig.height=4}
layout(matrix(c(1, 1, 2), nrow=1))

L <- data$N_factor1_levels
idx <- rep(1:L, each=2)
x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:L, function(l)
                    quantile(samples$delta_factor1[,l], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

mean_tau <- mean(samples$delta_factor1_tau)

lb <- min(c(-2.25 * mean_tau, cred[1,]))
ub <- max(c(+2.25 * mean_tau, cred[9,]))

par(mar=c(5, 5, 3, 1))
plot(1, type="n", main="Factor One Contributions",
     xlim=c(0.5, L + 1.5), xlab="", xaxt="n",
     ylim=c(lb, ub), ylab="Marginal Posterior")

lines(c(0.5, L + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
lines(c(0.5, L + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
lines(c(0.5, L + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = c_light, border = NA)
polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = c_mid, border = NA)
polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = c_mid_highlight, border = NA)
for (l in 1:L)
  lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

axis(1, at=1:L, labels=sapply(1:L, function(l) paste("l1_", l, sep="")))

par(mar=c(5, 1, 3, 1))
u <- 1.25 * max(samples$delta_factor1_tau)
hist(samples$delta_factor1_tau, breaks=seq(0, u, u / 50), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
abline(v=mean_tau, col="gray80", lwd=2, lty=3)
```

Next the 25 Factor 2 hierarchies within the Factor 1 levels.

```{r, fig.height=4}
for (l1 in 1:data$N_factor1_levels) {
  layout(matrix(c(1, 1, 2), nrow=1))

  level_idx <- which(data$factor2_to_factor1 == l1)
  L <- length(level_idx)
  idx <- rep(1:L, each=2)
  x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

  probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
  cred <- sapply(level_idx, function(l)
                            quantile(samples$delta_factor2[,l], probs=probs))
  pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

  mean_tau <- mean(samples$delta_factor2_tau[,l1])

  lb <- min(c(-2.25 * mean_tau, cred[1,]))
  ub <- max(c(+2.25 * mean_tau,cred[9,]))

  title <- paste("Factor Two Contributions Nested\nWithin Factor One Level", l1)

  par(mar=c(5, 5, 3, 1))
  plot(1, type="n", main=title,
       xlim=c(0.5, L + 0.5), xlab="", xaxt="n",
       ylim=c(lb, ub), ylab="Marginal Posterior")

  lines(c(0.5, L + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
  lines(c(0.5, L + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
  lines(c(0.5, L + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

  polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
          col = c_light, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
          col = c_light_highlight, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
          col = c_mid, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
          col = c_mid_highlight, border = NA)
  for (l in 1:L)
    lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

  axis(1, at=1:L, sapply(level_idx, function(l) paste("l2_", l, sep="")))

  par(mar=c(5, 1, 3, 1))
  u <- 1.25 * max(samples$delta_factor2_tau[,l1])
  hist(samples$delta_factor2_tau[,l1], breaks=seq(0, u, u / 50), main="",
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
  abline(v=mean_tau, col="gray80", lwd=2, lty=3)
}
```

Finally we have the 125 Factor 3 hierarchies nested within the Factor 2 levels.

```{r, fig.height=4}
for (l2 in 1:data$N_factor2_levels) {
  layout(matrix(c(1, 1, 2), nrow=1))

  level_idx <- which(data$factor3_to_factor2 == l2)
  L <- length(level_idx)
  idx <- rep(1:L, each=2)
  x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

  probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
  cred <- sapply(level_idx, function(l)
    quantile(samples$delta_factor3[,l], probs=probs))
  pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

  mean_tau <- mean(samples$delta_factor3_tau[,l2])

  lb <- min(c(-2.25 * mean_tau, cred[1,]))
  ub <- max(c(+2.25 * mean_tau, cred[9,]))

  title <- paste("Factor Three Contributions Nested\nWithin Factor Two Level", l2)

  par(mar=c(5, 5, 3, 1))
  plot(1, type="n", main=title,
       xlim=c(0.5, L + 0.5), xlab="", xaxt="n",
       ylim=c(lb, ub), ylab="Marginal Posterior")

  lines(c(0.5, L + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
  lines(c(0.5, L + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
  lines(c(0.5, L + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

  polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
          col = c_light, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
          col = c_light_highlight, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
          col = c_mid, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
          col = c_mid_highlight, border = NA)
  for (l in 1:L)
    lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

  axis(1, at=1:L, sapply(level_idx, function(l) paste("l2_", l, sep="")))

  par(mar=c(5, 1, 3, 1))
  u <- 1.25 * max(samples$delta_factor3_tau[,l2])
  hist(samples$delta_factor3_tau[,l2], breaks=seq(0, u, u / 50), main="",
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
  abline(v=mean_tau, col="gray80", lwd=2, lty=3)
}
```

## Overlapping Factor Models in Action

Finally let's consider the basic implementation of an overlapping multifactor
model.

```{r}
data <- read_rdump("data/overlapping_multifactor.data.R")

names(data)
```

Here we have three overlapping factors.  The first contains five levels, the
second eight levels, and the third four levels.

```{r}
par(mar=c(5, 5, 3, 5))

par(mfrow=c(3, 1))

main_factor_names <- c("Main Factor 1", "Main Factor 2", "Main Factor 3")
for(f in 1:3) {
  hist(data$main_factor_level_idx[f,],
       breaks=seq(0.5, data$N_main_factor_levels[f] + 0.5, 1),
       main="", col=c_dark, border=c_dark_highlight,
       xlim=c(0.5, data$N_main_factor_levels[f]+ 0.5), xlab=main_factor_names[f],
       ylim=c(0, 200), ylab="Number of\nObservations")
}
```

In order to build the most general multifactor model possible we'll also need
the interaction levels derived from these three main factors.  In particular
we'll need three first-order interaction factors, one for each of the three
pairs of main factors, and one second-order interaction factor.

Fortunately we can construct these interaction factors programmatically in Stan.

```{r}
writeLines(readLines("stan_programs/construct_inter_idx_general.stan"))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
inter <- stan(file='stan_programs/construct_inter_idx_general.stan',
             data=data, iter=1, warmup=0, chains=1,
             algorithm="Fixed_param")
```

```{r}
inter_output <- extract(inter)

data$N_inter1_factors <- inter_output$N_inter1_factors[1]
data$N_inter1_factor_levels <- array(inter_output$N_inter1_factor_levels[1,])
data$inter1_factor1_idx <- inter_output$inter1_factor1_idx[1,]
data$inter1_factor2_idx <- inter_output$inter1_factor2_idx[1,]
data$inter1_factor_level_idx <- inter_output$inter1_factor_level_idx[1,,]
dim(data$inter1_factor_level_idx) <- c(data$N_inter1_factors, data$N)

data$N_inter2_factors <- inter_output$N_inter2_factors[1]
data$N_inter2_factor_levels <- array(inter_output$N_inter2_factor_levels[1,])
data$inter2_factor1_idx <- inter_output$inter2_factor1_idx[1,]
data$inter2_factor2_idx <- inter_output$inter2_factor2_idx[1,]
data$inter2_factor3_idx <- inter_output$inter2_factor3_idx[1,]
data$inter2_factor_level_idx <- inter_output$inter2_factor_level_idx[1,,]
dim(data$inter2_factor_level_idx) <- c(data$N_inter2_factors, data$N)
```

The first-order interaction factors feature many more levels and, consequently,
each of those levels are less populated than the main factor levels.

```{r}
par(mfrow=c(3, 1))

inter1_factor_names <- c("Interaction Factor 12",
                         "Interaction Factor 13",
                         "Interaction Factor 23")
for(f in 1:3) {
  hist(data$inter1_factor_level_idx[f,],
       breaks=seq(0.5, data$N_inter1_factor_levels[f] + 0.5, 1),
       main="", col=c_dark, border=c_dark_highlight,
       xlim=c(0.5, data$N_inter1_factor_levels[f]+ 0.5), xlab=inter1_factor_names[f],
       ylim=c(0, 60), ylab="Number of\nObservations")
}
```

This is only amplified in the second-order interaction factor.  Moreover the
deviations from uniformity in the main factors level occupancies are amplified,
and a few second-order interaction levels are significantly more populated than
the others.

```{r}
par(mfrow=c(1, 1))

inter2_factor_names <- c("Interaction Factor 123")
hist(data$inter2_factor_level_idx[1,],
     breaks=seq(0.5, data$N_inter2_factor_levels[1] + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_inter2_factor_levels[1]+ 0.5), xlab=inter2_factor_names[1],
     ylim=c(0, 25), ylab="Number of Observations")
```

Knowing that we have only three main factors we could code up all of the
contributions from the full residual expansion by hand.

```{r}
writeLines(readLines('stan_programs/overlapping_factors_hand.stan'))
```

This brute force approach, however, doesn't scale well when we have more than
three factors.  To allow for an arbitrary number of factors we can pack the
factor levels at each order into single arrays.  Note that this packing is
equivalent to the direct sum introduced in [Section 3.4](#sec:tensor)!

```{r}
writeLines(readLines("stan_programs/pack_idx.stan"))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
pack <- stan(file='stan_programs/pack_idx.stan', data=data,
             iter=1, warmup=0, chains=1, algorithm="Fixed_param")
```

```{r}
pack_output <- extract(pack)

data$N_all_main_factor_levels <- pack_output$N_all_main_factor_levels[1]
data$packed_main_factor_idx <- array(pack_output$packed_main_factor_idx[1,])
data$main_factor_start_idx <- array(pack_output$main_factor_start_idx[1,])
data$main_factor_end_idx <- array(pack_output$main_factor_end_idx[1,])

data$N_all_inter1_factor_levels <- pack_output$N_all_inter1_factor_levels[1]
data$packed_inter1_factor_idx <- array(pack_output$packed_inter1_factor_idx[1,])
data$inter1_factor_start_idx <- array(pack_output$inter1_factor_start_idx[1,])
data$inter1_factor_end_idx <- array(pack_output$inter1_factor_end_idx[1,])

data$N_all_inter2_factor_levels <- pack_output$N_all_inter2_factor_levels[1]
data$packed_inter2_factor_idx <- array(pack_output$packed_inter2_factor_idx[1,])
data$inter2_factor_start_idx <- array(pack_output$inter2_factor_start_idx[1,])
data$inter2_factor_end_idx <- array(pack_output$inter2_factor_end_idx[1,])
```

This allows us to build a Stan program that can accommodate any number of main
factors.  For example we could implement a monolithically centered
parameterization.

```{r}
writeLines(readLines('stan_programs/overlapping_factors_cp.stan'))
```

Knowing how fragile the monolithically centered parameterization is, however,
we really want a Stan program where we can configure the parameterization of
all of the hierarchical parameters across all orders of the residual expansion.

```{r}
writeLines(readLines('stan_programs/overlapping_factors_mixed.stan'))
```

That said, let's not get ahead of ourselves.  Instead of trying to fit the
entire residual expansion at once let's incorporate the contributions from each
order incrementally.

To critique each iteration of the overlapping multifactor model we'll use a
regularized $F$ statistic that is common in frequentist analysis of variance
estimation.  In each sufficiently occupied factor level, where a sufficiently
occupied level requires at least two observations, we'll compare the empirical
mean of the empirical variances, or the _within group variation_, to the
empirical variance of the empirical means, or the _between group variation_. 
Because the factor heterogeneity should manifest directly in the mean of the
observations here this regularized $F$ statistic should be relatively sensitive
to excess heterogeneity.

```{r}
writeLines(readLines('stan_programs/compute_f_stat.stan'))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/compute_f_stat.stan', data=data, seed=93585393,
             iter=1, warmup=0, chains=1, algorithm="Fixed_param")

F_main_obs <- extract(fit)$F_main_obs[1,]
F_inter1_obs <- extract(fit)$F_inter1_obs[1,]
F_inter2_obs <- extract(fit)$F_inter2_obs[1,]
```

With the observed summary statistics evaluated and saved we can start working
through the residual expansion.  We begin with a baseline only model.

```{r}
writeLines(readLines("stan_programs/overlapping_factors_ver0.stan"))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/overlapping_factors_ver0.stan',
            data=data, seed=4838282, refresh=2000)
```

There are no indications of computational problems.

```{r}
util$check_all_diagnostics(fit)
```

The posterior retrodictive check based on the $F$ statistic, however, suggests
that the baseline model is poorly capturing the heterogeneity across the main
factor levels observed in the data.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 3))
par(mar=c(5, 5, 3, 1))

lims <- c(100, 600, 100)
deltas <- c(2, 10, 2)

for (f in 1:3) {
  hist(samples$F_main_post_pred[,f], breaks=seq(0, 900, deltas[f]),
       main=main_factor_names[f],
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
  abline(v=F_main_obs[f], col="black", lty=1, lw=2)
}
```

To do better we incorporate the contributions from the main factor levels.

```{r}
writeLines(readLines("stan_programs/overlapping_factors_ver1.stan"))
```

We start with a monolithically non-centered parameterization.

```{r}
data$main_cp_idx <- vector()
data$L_main_cp <- length(data$main_cp_idx)

data$main_ncp_idx <- setdiff(1:data$N_all_main_factor_levels, data$main_cp_idx)
data$L_main_ncp <- length(data$main_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/overlapping_factors_ver1.stan',
            data=data, seed=4838282, refresh=2000)
```

Fortunately there don't seem to be any computational problems.

```{r}
util$check_all_diagnostics(fit)
```

The posterior retrodictive checks, however, look unsatisfying.  Our model is
unable to capture not only the heterogeneity across the first-order interaction
levels but also the heterogeneity across the Main Factor 2 levels, even though
we've already added a hierarchy for this factor!

```{r}
samples <- extract(fit)

par(mfrow=c(2, 3))

lims <- c(100, 900, 200)
deltas <- c(1, 10, 2)

for (f in 1:3) {
  hist(samples$F_main_post_pred[,f], breaks=seq(0, 900, deltas[f]),
       main=main_factor_names[f],
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
  abline(v=F_main_obs[f], col="black", lty=1, lw=2)
}

lims <- c(2000, 250, 2500)
deltas <- c(20, 5, 20)

for (f in 1:3) {
  hist(samples$F_inter1_post_pred[,f], breaks=seq(0, 2500, deltas[f]),
       main=inter1_factor_names[f],
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
  abline(v=F_inter1_obs[f], col="black", lty=1, lw=2)
}
```

Poor modeling of the heterogeneity across main factor levels despite modeling
those levels is a common indicator of strong interaction heterogeneity, further
supporting the need to incorporate the first-order interaction factors.

```{r}
writeLines(readLines("stan_programs/overlapping_factors_ver2.stan"))
```

Again we begin with a non-centered parameterization.

```{r}
data$inter1_cp_idx <- vector()
data$L_inter1_cp <- length(data$inter1_cp_idx)

data$inter1_ncp_idx <- setdiff(1:data$N_all_inter1_factor_levels,
                                    data$inter1_cp_idx)
data$L_inter1_ncp <- length(data$inter1_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/overlapping_factors_ver2.stan',
            data=data, seed=4838282, refresh=2000)
```

Diagnostics are clean.

```{r}
util$check_all_diagnostics(fit)
```

The posterior retrodictive checks for the main factors and the first-order
interaction factors all look much better, and the check for the second-order
interaction factor suggests that we can't resolve any higher-order 
contributions.

```{r}
samples <- extract(fit)

par(mfrow=c(3, 3))

lims <- c(100, 700, 200)
deltas <- c(1, 10, 2)

for (f in 1:3) {
  hist(samples$F_main_post_pred[,f], breaks=seq(0, 900, deltas[f]),
       main=main_factor_names[f],
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
  abline(v=F_main_obs[f], col="black", lty=1, lw=2)
}

lims <- c(1500, 250, 2000)
deltas <- c(20, 5, 20)

for (f in 1:3) {
  hist(samples$F_inter1_post_pred[,f], breaks=seq(0, 2500, deltas[f]),
       main=inter1_factor_names[f],
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
  abline(v=F_inter1_obs[f], col="black", lty=1, lw=2)
}

plot.new()
for (f in 1:1) {
  hist(samples$F_inter2_post_pred[,f], breaks=seq(4000, 20000, 100),
       main=inter2_factor_names[f],
       col=c_dark, border=c_dark_highlight,
       xlim=c(5000, 16000), xlab="F Statistic", yaxt='n', ylab="")
  abline(v=F_inter2_obs[f], col="black", lty=1, lw=2)
}
```

To be safe, however, let's include the second-order interactions and investigate
the corresponding inferences.

```{r}
writeLines(readLines("stan_programs/overlapping_factors_ver3.stan"))
```

Per usual we default to non-centering the residual parameters for the levels
within this new factor.

```{r}
data$inter2_cp_idx <- vector()
data$L_inter2_cp <- length(data$inter2_cp_idx)

data$inter2_ncp_idx <- setdiff(1:data$N_all_inter2_factor_levels,
                               data$inter2_cp_idx)
data$L_inter2_ncp <- length(data$inter2_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/overlapping_factors_ver3.stan',
            data=data, seed=4838282, refresh=2000)
```

Unfortunately this proves to be a poor choice.

```{r}
util$check_all_diagnostics(fit)
```

While there are only a few divergences we cannot let down our guard.

```{r}
partition <- util$partition_div(fit)
div_samples <- partition[[1]]
nondiv_samples <- partition[[2]]
```

The levels of Main Factor 1 exhibit some mild inverted funnel geometry, but
nothing too problematic.

```{r, fig.height=2}
f <- 1
par(mfrow=c(1, 3))

for (l in data$main_factor_start_idx[f]:data$main_factor_end_idx[f]) {
  if (l %in% data$main_cp_idx) {
    cp_idx <- which(l == data$main_cp_idx)
    name_x <- paste("packed_delta_main_cp[", cp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  } else {
    ncp_idx <- which(l == data$main_ncp_idx)
    name_x <- paste("packed_delta_main_ncp[", ncp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  }

  title=paste(main_factor_names[f],
              ",\nLevel = ", l - data$main_factor_start_idx[f] + 1, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-8, 8),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-4, 3))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

Main Factor 2 enjoys stronger partial pooling, but maybe not enough to suppress
the inverted funnel geometry towards larger population scales.  These are our
chief suspects.

```{r, fig.height=2}
f <- 2
par(mfrow=c(1, 3))

for (l in data$main_factor_start_idx[f]:data$main_factor_end_idx[f]) {
  if (l %in% data$main_cp_idx) {
    cp_idx <- which(l == data$main_cp_idx)
    name_x <- paste("packed_delta_main_cp[", cp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  } else {
    ncp_idx <- which(l == data$main_ncp_idx)
    name_x <- paste("packed_delta_main_ncp[", ncp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  }

  title=paste(main_factor_names[f],
              ", Level = ", l - data$main_factor_start_idx[f] + 1, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-8, 8),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(0, 3))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

Similarly Main Factor 3 looks okay, likely due to the stronger aggregation of
data into each of the fewer levels.

```{r}
f <- 3
par(mfrow=c(2, 2))

for (l in data$main_factor_start_idx[f]:data$main_factor_end_idx[f]) {
  if (l %in% data$main_cp_idx) {
    cp_idx <- which(l == data$main_cp_idx)
    name_x <- paste("packed_delta_main_cp[", cp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  } else {
    ncp_idx <- which(l == data$main_ncp_idx)
    name_x <- paste("packed_delta_main_ncp[", ncp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  }

  title=paste(main_factor_names[f],
              ", Level = ", l - data$main_factor_start_idx[f] + 1, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-8, 8),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-1, 3))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

What about the first-order interactions?  Nothing too suspicious.

```{r, fig.height=2}
par(mar=c(5, 5, 3, 1))

f <- 1
par(mfrow=c(1, 4))

for (l in data$inter1_factor_start_idx[f]:data$inter1_factor_end_idx[f]) {
  if (l %in% data$inter1_cp_idx) {
    cp_idx <- which(l == data$inter1_cp_idx)
    name_x <- paste("packed_delta_inter1_cp[", cp_idx, "]", sep='')
    name_y <- paste("delta_inter1_tau[", data$packed_inter1_factor_idx[l], "]", sep='')
  } else {
    ncp_idx <- which(l == data$inter1_ncp_idx)
    name_x <- paste("packed_delta_inter1_ncp[", ncp_idx, "]", sep='')
    name_y <- paste("delta_inter1_tau[", data$packed_inter1_factor_idx[l], "]", sep='')
  }

  title=paste(inter1_factor_names[f],
              ",\nLevel = ", l - data$inter1_factor_start_idx[f] + 1, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-8, 8),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(0, 2))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}


f <- 2
par(mfrow=c(1, 4))

for (l in data$inter1_factor_start_idx[f]:data$inter1_factor_end_idx[f]) {
  if (l %in% data$inter1_cp_idx) {
    cp_idx <- which(l == data$inter1_cp_idx)
    name_x <- paste("packed_delta_inter1_cp[", cp_idx, "]", sep='')
    name_y <- paste("delta_inter1_tau[", data$packed_inter1_factor_idx[l], "]", sep='')
  } else {
    ncp_idx <- which(l == data$inter1_ncp_idx)
    name_x <- paste("packed_delta_inter1_ncp[", ncp_idx, "]", sep='')
    name_y <- paste("delta_inter1_tau[", data$packed_inter1_factor_idx[l], "]", sep='')
  }

  title=paste(inter1_factor_names[f],
              ",\nLevel = ", l - data$inter1_factor_start_idx[f] + 1, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-8, 8),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-8, 1))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}

f <- 3
par(mfrow=c(1, 4))

for (l in data$inter1_factor_start_idx[f]:data$inter1_factor_end_idx[f]) {
  if (l %in% data$inter1_cp_idx) {
    cp_idx <- which(l == data$inter1_cp_idx)
    name_x <- paste("packed_delta_inter1_cp[", cp_idx, "]", sep='')
    name_y <- paste("delta_inter1_tau[", data$packed_inter1_factor_idx[l], "]", sep='')
  } else {
    ncp_idx <- which(l == data$inter1_ncp_idx)
    name_x <- paste("packed_delta_inter1_ncp[", ncp_idx, "]", sep='')
    name_y <- paste("delta_inter1_tau[", data$packed_inter1_factor_idx[l], "]", sep='')
  }

  title=paste(inter1_factor_names[f],
              ",\nLevel = ", l - data$inter1_factor_start_idx[f] + 1, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-8, 8),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-1, 2))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

Finally the second-order interaction levels also look unproblematic.  To avoid
an overwhelming number of plots let's peruse just the first sixteen levels.

```{r, fig.height=2}
f <- 1
par(mfrow=c(1, 4))

for (l in 1:16) {
  if (l %in% data$inter2_cp_idx) {
    cp_idx <- which(l == data$inter2_cp_idx)
    name_x <- paste("packed_delta_inter2_cp[", cp_idx, "]", sep='')
    name_y <- paste("delta_inter2_tau[", data$packed_inter2_factor_idx[l], "]", sep='')
  } else {
    ncp_idx <- which(l == data$inter2_ncp_idx)
    name_x <- paste("packed_delta_inter2_ncp[", ncp_idx, "]", sep='')
    name_y <- paste("delta_inter2_tau[", data$packed_inter2_factor_idx[l], "]", sep='')
  }

  title=paste(inter2_factor_names[f],
              ",\nLevel = ", l - data$inter2_factor_start_idx[f] + 1, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-8, 8),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-8, 1))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

Because the Main Factor 2 levels exhibited the worst geometry let's try
centering those parameters and trying the fit again.

```{r}
data$main_cp_idx <- data$main_factor_start_idx[2]:data$main_factor_end_idx[2]
data$L_main_cp <- length(data$main_cp_idx)

data$main_ncp_idx <- setdiff(1:data$N_all_main_factor_levels, data$main_cp_idx)
data$L_main_ncp <- length(data$main_ncp_idx)

data$inter2_cp_idx <- vector()
data$L_inter2_cp <- length(data$inter2_cp_idx)

data$inter2_ncp_idx <- setdiff(1:data$N_all_inter2_factor_levels,
                               data$inter2_cp_idx)
data$L_inter2_ncp <- length(data$inter2_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/overlapping_factors_ver3.stan',
            data=data, seed=4838282, refresh=2000)
```

Fortunately that resolved all of our problems!

```{r}
util$check_all_diagnostics(fit)
```

Why did we have to center the Main Factor 2 levels only after adding the
second-order interaction factors but not before?  Remember that none of the
residual contributions influence the likelihood function independently of the
others.  When higher-order contributions are non-zero their addition can give
the lower-order residuals freedom to explore different configurations, and
unfortunately sometimes even more computationally pathological configurations.

In any case our careful centering seems to have done the trick and we can move
onto posterior inferences.  First our posterior retrodicive checks have not 
gotten any worse.

```{r}
samples <- extract(fit)

par(mfrow=c(3, 3))

lims <- c(100, 700, 200)
deltas <- c(2, 10, 2)

for (f in 1:3) {
  hist(samples$F_main_post_pred[,f], breaks=seq(0, 700, deltas[f]),
       main=main_factor_names[f],
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
  abline(v=F_main_obs[f], col="black", lty=1, lw=2)
}

lims <- c(1500, 250, 2000)
deltas <- c(20, 5, 20)

for (f in 1:3) {
  hist(samples$F_inter1_post_pred[,f], breaks=seq(0, 1500, deltas[f]),
       main=inter1_factor_names[f],
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
  abline(v=F_inter1_obs[f], col="black", lty=1, lw=2)
}

plot.new()
for (f in 1:1) {
  hist(samples$F_inter2_post_pred[,f], breaks=seq(4000, 20000, 100),
       main=inter2_factor_names[f],
       col=c_dark, border=c_dark_highlight,
       xlim=c(5000, 16000), xlab="F Statistic", yaxt='n', ylab="")
  abline(v=F_inter2_obs[f], col="black", lty=1, lw=2)
}
```

Satisfied that the full residual expansion adequately captures the features of
the true data generating process that we can resolve with the given data, we can
now consider posterior inferences.  First let's look at the baseline parameter.

```{r}
par(mfrow=c(1, 1))
par(mar=c(5, 5, 3, 5))

hist(samples$baseline, breaks=seq(-10, 20, 0.25), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(-10, 20), xlab="Baseline", yaxt='n', ylab="")
```

Then we can consider the main factor contributions to the overall heterogeneity.

```{r, fig.height=4}
plot_factor_posteriors <- function(type, title, f) {
  layout(matrix(c(1, 1, 2), nrow=1))
 
  par(mar=c(5, 5, 3, 1))

  L <- data[paste("N_", type, "_factor_levels", sep="")][[1]][f]
  level_idx <- data[paste(type, "_factor_start_idx", sep="")][[1]][f]:
               data[paste(type, "_factor_end_idx", sep="")][[1]][f]

  idx <- rep(1:L, each=2)
  x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

  probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
  cred <- sapply(level_idx, function(l)
                   quantile(samples[paste("packed_delta_", type, sep="")][[1]][,l], probs=probs))
  pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9,n]))

  mean_tau <- mean(samples[paste("delta_", type, "_tau", sep="")][[1]][,f])

  l <- min(c(-2.25 * mean_tau, cred[1,]))
  u <- max(c(2.25 * mean_tau,  cred[9,]))
 
  plot(1, type="n", main=title,
       xlim=c(0.5, L + 0.5), xlab="Level",
       ylim=c(l, u), ylab="Marginal Posterior")

  lines(c(0.5, L + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
  lines(c(0.5, L + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
  lines(c(0.5, L + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

  polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
          col = c_light, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
          col = c_light_highlight, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
          col = c_mid, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
          col = c_mid_highlight, border = NA)
  for (l in 1:L)
    lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

  par(mar=c(5, 1, 3, 1))

  u <- 1.25 * max(samples[paste("delta_", type, "_tau", sep="")][[1]][,f])
  hist(samples[paste("delta_", type, "_tau", sep="")][[1]][,f], breaks=seq(0, u, u / 50),
       main=title,
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
  abline(v=mean_tau, col="gray80", lwd=2, lty=3)
}

plot_factor_posteriors("main", "Main Factor 1", 1)
plot_factor_posteriors("main", "Main Factor 2", 2)
plot_factor_posteriors("main", "Main Factor 3", 3)
```

Then the first-order interaction contributions to the overall heterogeneity.

```{r, fig.height=4}
plot_factor_posteriors("inter1", "Interaction 12", 1)
plot_factor_posteriors("inter1", "Interaction 13", 2)
plot_factor_posteriors("inter1", "Interaction 23", 3)
```

Finally we can examine the second-order interaction contributions, which are
largely consistent with zero given the resolution afforded by the observed data.
This in particular verifies the previous Interaction 123 posterior retrodictive
check.

```{r, fig.height=4}
plot_factor_posteriors("inter2", "Interaction 123", 1)
```

Once we have an adequate model we can then consider applying its inferences
beyond the scope of the given measurement.  For example let's consider using
our inferences to inform predictions for an entirely new circumstance.

```{r}
pred_data <- read_rdump("data/overlapping_multifactor_pred.data.R")

names(pred_data)
```

Because the main factor level occupancies vary considerably in this new
circumstance we can't just naively extrapolate predictions from our previous
fit.

```{r}
par(mfrow=c(1, 3))

for (f in 1:data$N_main_factors) {
  hist(data$main_factor_level_idx[f,],
       breaks=1:(data$N_main_factor_levels[f]+1)-0.5,
       main=main_factor_names[f], col=c_light_trans, border=c_light,
       xlim=c(0, data$N_main_factor_levels[f]+1), xlab="Level",
       ylim=c(0, 200), yaxt='n', ylab="")
  hist(pred_data$main_factor_level_idx[f,],
       breaks=1:(data$N_main_factor_levels[f]+1)-0.45,
       col=c_dark_trans, border=c_dark, add=T)
  text(0, 185, label="In-Sample", pos=4, col=c_light)
  text(0, 175, label="Out-of-Sample", pos=4, col=c_dark)
}
```

What we can do, however, is _reconstruct_ the proper heterogeneity in the
new factor configurations to generate predictions specific to the new
circumstance.  First we have to build all of the interaction factors for these
new factor configurations.

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
inter <- stan(file='stan_programs/construct_inter_idx_general.stan',
              data=pred_data, iter=1, warmup=0, chains=1,
              algorithm="Fixed_param")
```

```{r}
inter_output <- extract(inter)

data$pred_N <- pred_data$N
data$pred_main_factor_level_idx <- pred_data$main_factor_level_idx
data$pred_inter1_factor_level_idx <- inter_output$inter1_factor_level_idx[1,,]
dim(data$pred_inter1_factor_level_idx) <- c(data$N_inter1_factors, data$pred_N)
data$pred_inter2_factor_level_idx <- inter_output$inter2_factor_level_idx[1,,]
dim(data$pred_inter2_factor_level_idx) <- c(data$N_inter2_factors, data$pred_N)
```

Unsurprisingly the interaction factor level occupancies also vary considerably.

```{r}
par(mfrow=c(2, 3))

names <- c("Interaction Factor 12", "Interaction Factor 13", "Interaction Factor 23")
for (f in 1:data$N_inter1_factors) {
  hist(data$inter1_factor_level_idx[f,],
       breaks=1:(data$N_inter1_factor_levels[f]+1)-0.5,
       main=names[f], col=c_light_trans, border=c_light,
       xlim=c(0, data$N_inter1_factor_levels[f]+1), xlab="Level",
       ylim=c(0, 100), yaxt='n', ylab="")
  hist(data$pred_inter1_factor_level_idx[f,],
       breaks=1:(data$N_inter1_factor_levels[f]+1)-0.45,
       col=c_dark_trans, border=c_dark, add=T)
}

plot.new()

names <- c("Interaction Factor 123")
for (f in 1:data$N_inter2_factors) {
  hist(data$inter2_factor_level_idx[f,],
       breaks=1:(data$N_inter2_factor_levels[f]+1)-0.5,
       main=names[f], col=c_light_trans, border=c_light,
       xlim=c(0, data$N_inter2_factor_levels[f]+1), xlab="Level",
       ylim=c(0, 25), yaxt='n', ylab="")
  hist(data$pred_inter2_factor_level_idx[f,],
       breaks=1:(data$N_inter2_factor_levels[f]+1)-0.45,
       col=c_dark_trans, border=c_dark, add=T)
}
```

For each factor configuration in this new, external data set we can reconstruct
the expected behavior using the posterior inferences for the residual
contributions.  Provided that whatever latent process that generates the
heterogeneity generalizes to the new circumstance this should yield reasonably
accurate predictions.

```{r}
writeLines(readLines("stan_programs/overlapping_factors_ver2_pred.stan"))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/overlapping_factors_ver2_pred.stan',
            data=data, seed=4838282, refresh=2000)
```

Indeed the reconstructed predictions using the new factor configurations are
substantially different to those generated from the the old factor
configurations.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1))

hist(samples$y_post_pred, breaks=seq(-15, 40, 0.25),
     main="Aggregate Predictions", col=c_light_trans, border=c_light,
     xlim=c(-15, 25), xlab="y",
     ylim=c(0, 30000), yaxt='n', ylab="")
hist(samples$y_post_out_pred, breaks=seq(-15, 40, 0.25),
     col=c_dark_trans, border=c_dark, add=T)
text(-10, 7000, label="In-Sample", pos=4, col=c_light)
text(-10, 5000, label="Out-of-Sample", pos=4, col=c_dark)
```

In this case naively extrapolating predictions from our initial fit would lead
to poor predictive performance.  Because we learn how each main factor, and
their interactions, contribute to the overall behavior, however, we can readily
adapt to new factor configurations and ensure much better predictive
performance.  That is at least whenever the actual source of the heterogeneity
is constant.

# Case Studies

Comfortable with the basics of implementing factor models we can now consider
some slightly less artificial examples that demonstrate how we might use this
modeling technique in actual practice.  Our first case study will utilize
nested multifactor modeling while our second will utilize overlapping factor
modeling.

## Batch Variation

Let's begin by expanding upon the analog-to-digital example from my
[hierarchical modeling case study](https://betanalpha.github.io/assets/case_studies/hierarchical_modeling.html).

Recall that an analog-to-digital detector converts some continuous, or analog,
input to some discrete, or digital, output.  If the input signal $I$ is measured
relative to some reference input, $I_{0}$, then we might model the discrete
output with a Poisson observational model,
$$
\begin{align*}
y &\sim \text{Poisson}(\lambda)
\\
\lambda &= \psi \cdot \frac{I}{I_{0}}
\\
&\equiv \psi \cdot \rho_{I},
\end{align*}
$$
where $\psi$ is the _calibration coefficient_.

In this case we receive sixteen detectors from the manufacturer in four
shipments, but we're not sure how consistently the calibration coefficient
behaves both between shipments and within shipments.  Moreover the output of
each detector might also vary depending on exactly where the input signal
strikes, suggesting additional heterogeneity in the calibration coefficient
across four spatial regions in the active area of each detector.

Because the spatial regions are nested within each detector, and each detector
is nested within a shipment, we are naturally lead to consider a nested
multifactor model for the calibration coefficient, with Factor 1 identifying
each shipment, Factor 2 identifying each detector, and Factor 3 identifying each
of the possible spatial regions across all of those detectors.

```{r}
data <- read_rdump("data/batch.data.R")

names(data)
```

The four spatial regions across the sixteen detectors yields
`N_factor3_levels = 64` levels in the shallowest factor.  For each of these
factors we record the digital output from fifteen analog input signals.

```{r}
par(mfrow=c(1, 1))
par(mar=c(5, 5, 3, 5))

hist(data$obs_to_factor3, breaks=seq(0.5, data$N_factor3_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor3_levels + 0.5), xlab="Factor Three Levels",
     ylim=c(0, 20), ylab="Number of Observations")
```

Factor 2 contains sixteen levels, one for each of the delivered detectors.  The
four Factor 3 levels corresponding to the spatial regions of each detector nest
within the Factor 2 levels.

```{r}
hist(data$factor3_to_factor2, breaks=seq(0.5, data$N_factor2_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor2_levels + 0.5), xlab="Factor Two Levels",
     ylim=c(0, 5), ylab="Number of Factor Three Levels")
```

```{r}
hist(data$factor3_to_factor2[data$obs_to_factor3],
     breaks=seq(0.5, data$N_factor2_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor2_levels + 0.5), xlab="Factor Two Levels",
     ylim=c(0, 75), ylab="Number of Observations")
```

Finally those sixteen detector levels nest within four shipment levels.

```{r}
hist(data$factor2_to_factor1, breaks=seq(0.5, data$N_factor1_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor1_levels + 0.5), xlab="Factor One Levels",
     ylim=c(0, 5), ylab="Number of Factor Two Levels")
```

```{r}
hist(data$factor2_to_factor1[data$factor3_to_factor2[data$obs_to_factor3]],
     breaks=seq(0.5, data$N_factor1_levels + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_factor1_levels + 0.5), xlab="Factor One Levels",
     ylim=c(0, 250), ylab="Number of Observations")
```

To isolate heterogeneity due to the calibration coefficient for posterior
retrodictive checks let's consider the variation of the normalized digital
outputs,
$$
\frac{ y_{n} }{ \rho_{I, n} },
$$
across the Factor 3 levels.  As before we summarize this variation with a
regularized $F$ statistic.

```{r}
writeLines(readLines("stan_programs/batch_f_stat.stan"))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/batch_f_stat.stan', data=data, seed=93585393,
            iter=1, warmup=0, chains=1, algorithm="Fixed_param")

F_obs <- extract(fit)$F[1]
```

For a less overwhelming modeling experience we start simple and iterate,
beginning with a baseline only model.  Before fitting, however, we want to look
at the prior consequences for the population of calibration coefficients to
ensure that they don't conflict with our domain expertise.

Here we generate prior samples using Hamiltonian Monte Carlo.

```{r}
writeLines(readLines("stan_programs/batch_ver0_prior.stan"))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/batch_ver0_prior.stan',
            data=data, init_r=1, seed=4838282, refresh=1000)
```

```{r}
util$check_all_diagnostics(fit)
```

With no indications of computational problems we can investigate the prior
behavior for the calibration coefficients, $\psi$, in the spatial region of
each detector.  In this case the calibration coefficients are identical and
distributed exactly the same as the exponential of the baseline parameter.  The
exponential does induce a heavy tail towards large values, but nothing
outrageous.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1))

hist(exp(samples$log_psi), breaks=seq(0, 35, 0.25), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 15), xlab="psi", yaxt='n', ylab="")
```

To fit the posterior we just have to add the observations to the `data` block,
the contribution of the observational model to the `model` block, and the
evaluation of the $F$ statistic in the `functions` and `generated quantities`
blocks.

```{r}
writeLines(readLines("stan_programs/batch_ver0.stan"))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/batch_ver0.stan',
            data=data, init_r=1, seed=4838282, refresh=1000)
```

```{r}
util$check_all_diagnostics(fit)
```

With the fit looking okay we next consider the posterior retrodictive checks.
Unfortunately our baseline only model does a terrible job of capturing the
heterogeneity observed in the data.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1))

hist(samples$F_post_pred, breaks=seq(0, 6000, 50),
     main="Posterior Retrodictive Checks",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 6000), xlab="F Statistic", yaxt='n', ylab="")
abline(v=F_obs, col="white", lty=1, lw=3)
abline(v=F_obs, col="black", lty=1, lw=2)
```

At the same time the posterior retrodictive distribution of digital outputs is
remarkably different between the observed outputs, corroborating the
inadequacy of our initial model.

```{r}
B <- 101
breaks <- seq(-0.5, B - 0.5, 1)

idx <- rep(1:B, each=2)
xs <- sapply(1:length(idx), function(b) if(b %% 2 == 0) idx[b] + 0.5 else idx[b] - 0.5)

obs <- hist(data$y, breaks=breaks, plot=FALSE)$counts
pad_obs <- do.call(cbind, lapply(idx, function(n) obs[n]))

post_pred <- sapply(1:4000, function(n) hist(samples$y_post_pred[n,],
                                             breaks=breaks, plot=FALSE)$counts)
probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:B, function(b) quantile(post_pred[b,], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

plot(1, type="n", main="Posterior Retrodictive Distribution",
     xlim=c(-0.5, B - 0.5), xlab="y",
     ylim=c(0, max(c(obs, cred[9,]))), ylab="")

polygon(c(xs, rev(xs)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = c_light, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = c_mid, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = c_mid_highlight, border = NA)
lines(xs, pad_cred[5,], col=c_dark, lwd=2)

lines(xs, pad_obs, col="white", lty=1, lw=2.5)
lines(xs, pad_obs, col="black", lty=1, lw=2)
```

To improve our model we next incorporate heterogeneity across the four
shipments.  First we check the prior model, fitting a non-centered
parameterization of the Factor 1 hierarchy with Hamiltonian Monte Carlo.

```{r}
writeLines(readLines("stan_programs/batch_ver1_prior.stan"))
```

```{r}
data$factor1_cp_idx <- vector()
data$L_factor1_cp <- length(data$factor1_cp_idx)

data$factor1_ncp_idx <- setdiff(1:data$N_factor1_levels, data$factor1_cp_idx)
data$L_factor1_ncp <- length(data$factor1_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/batch_ver1_prior.stan',
            data=data, init_r=1, seed=4838282, refresh=1000)
```

```{r}
util$check_all_diagnostics(fit)
```

The added variation around the logarithmic baseline induces an even heavier tail
on the prior model for the calibration coefficients, but that tail is still
reasonable with only a relatively small probability allocated to extreme
calibration coefficients.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1))

hist(exp(samples$log_psi[samples$log_psi < 4]),
     breaks=seq(0, 100, 0.25), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 25), xlab="Psi", yaxt='n', ylab="")
```

Adding the observational model updates the prior Stan program into a posterior
Stan program.

```{r}
writeLines(readLines("stan_programs/batch_ver1.stan"))
```

We'll fit using the same non-centered parameterization we set just above.

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/batch_ver1.stan',
            data=data, init_r=1, seed=4838282, refresh=1000)
```

Ooph.

```{r}
util$check_all_diagnostics(fit)
```

Let's go hunting.

```{r}
partition <- util$partition_div(fit)
div_samples <- partition[[1]]
nondiv_samples <- partition[[2]]
```

Because we have only one hierarchy here the investigation is pretty
straightforward.  All of the Factor 1 level parameters exhibit an inverted
funnel, and the divergences concentrate at large values of the population scale.

```{r}
par(mfrow=c(1, data$N_factor1_levels))
par(mar=c(5, 4, 3, 2), oma = c(0, 0, 2, 0))

for (l in 1:data$N_factor1_levels) {
  if (l %in% data$factor1_cp_idx) {
    cp_idx <- which(l == data$factor1_cp_idx)
    name_x <- paste("delta_factor1_cp[", cp_idx, "]", sep='')
  } else {
    ncp_idx <- which(l == data$factor1_ncp_idx)
    name_x <- paste("delta_factor1_ncp[", ncp_idx, "]", sep='')
  }
  name_y <- "delta_factor1_tau"

  title=paste("Factor One Level = ", l, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-6, 6),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-2, 1))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}

mtext("Factor One Hierarchy", outer=TRUE)
```

This immediately suggests a monolithically centered parameterization, which
in hindsight isn't that surprising given the strong aggregation of data into
these deeper levels.

```{r}
data$factor1_cp_idx <- 1:data$N_factor1_levels
data$L_factor1_cp <- length(data$factor1_cp_idx)

data$factor1_ncp_idx <- setdiff(1:data$N_factor1_levels, data$factor1_cp_idx)
data$L_factor1_ncp <- length(data$factor1_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/batch_ver1.stan',
            data=data, init_r=1, seed=4838282, refresh=1000)
```

Much better.

```{r}
util$check_all_diagnostics(fit)
```

Unfortunately while the shipment heterogeneity does improve our fit, the data
still exhibits significantly more variation.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1))

hist(samples$F_post_pred, breaks=seq(0, 6000, 50),
     main="Posterior Retrodictive Checks",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 6000), xlab="F Statistic", yaxt='n', ylab="")
abline(v=F_obs, col="white", lty=1, lw=3)
abline(v=F_obs, col="black", lty=1, lw=2)
```

The overall distribution of the observations also hints as a poor fit.  The
observed data are skewed towards lower values and don't exhibit the shoulder
seen in the posterior retrodictions.

```{r}
B <- 101
breaks <- seq(-0.5, B - 0.5, 1)

idx <- rep(1:B, each=2)
xs <- sapply(1:length(idx), function(b) if(b %% 2 == 0) idx[b] + 0.5 else idx[b] - 0.5)

obs <- hist(data$y, breaks=breaks, plot=FALSE)$counts
pad_obs <- do.call(cbind, lapply(idx, function(n) obs[n]))

post_pred <- sapply(1:4000, function(n) hist(samples$y_post_pred[n,],
                                             breaks=breaks,
                                             plot=FALSE)$counts)
probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:B, function(b) quantile(post_pred[b,], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

plot(1, type="n", main="Posterior Retrodictive Distribution",
     xlim=c(-0.5, B - 0.5), xlab="y",
     ylim=c(0, max(c(obs, cred[9,]))), ylab="")

polygon(c(xs, rev(xs)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = c_light, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = c_mid, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = c_mid_highlight, border = NA)
lines(xs, pad_cred[5,], col=c_dark, lwd=2)

lines(xs, pad_obs, col="white", lty=1, lw=2.5)
lines(xs, pad_obs, col="black", lty=1, lw=2)
```

And so we continue on, this time incorporating the detector heterogeneity within
each shipment.

```{r}
writeLines(readLines("stan_programs/batch_ver2_prior.stan"))
```

For the prior fit we want to make sure to monolithically non-center all of the
hierarchies.

```{r}
data$factor1_cp_idx <- vector()
data$L_factor1_cp <- length(data$factor1_cp_idx)

data$factor1_ncp_idx <- setdiff(1:data$N_factor1_levels, data$factor1_cp_idx)
data$L_factor1_ncp <- length(data$factor1_ncp_idx)

data$factor2_cp_idx <- vector()
data$L_factor2_cp <- length(data$factor2_cp_idx)

data$factor2_ncp_idx <- setdiff(1:data$N_factor2_levels, data$factor2_cp_idx)
data$L_factor2_ncp <- length(data$factor2_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/batch_ver2_prior.stan',
            data=data, init_r=1, seed=4838282, refresh=1000)
```

```{r}
util$check_all_diagnostics(fit)
```

As before the added variation fattens the tail on the calibration coefficients
a bit, but there is still no real cause for concern.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1))

hist(exp(samples$log_psi[samples$log_psi < 4]),
     breaks=seq(0, 100, 0.25), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 25), xlab="Psi", yaxt='n', ylab="")
```

On to Cincinnati.  I mean the posterior distribution.

```{r}
writeLines(readLines("stan_programs/batch_ver2.stan"))
```

Given the lessons from the fit of the previous model we'll want to center the
shipment levels again, but we'll start with a non-centered parameterization of
the detector levels.

```{r}
data$factor1_cp_idx <- 1:data$N_factor1_levels
data$L_factor1_cp <- length(data$factor1_cp_idx)

data$factor1_ncp_idx <- setdiff(1:data$N_factor1_levels, data$factor1_cp_idx)
data$L_factor1_ncp <- length(data$factor1_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/batch_ver2.stan',
            data=data, init_r=1, seed=4838282, refresh=1000)
```

Looks like we hit on a decent parameterization.

```{r}
util$check_all_diagnostics(fit)
```

The posterior retrodictive distribution for the $F$ statistic crawls up towards
the observed value, but still not enough.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1))

hist(samples$F_post_pred, breaks=seq(0, 6000, 50),
     main="Posterior Retrodictive Checks",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 6000), xlab="F Statistic", yaxt='n', ylab="")
abline(v=F_obs, col="white", lty=1, lw=3)
abline(v=F_obs, col="black", lty=1, lw=2)
```

Similarly the posterior retrodictive histograms for the entire observation are
still not able to capture the skew of the observed histogram.

```{r}
B <- 101
breaks <- seq(-0.5, B - 0.5, 1)

idx <- rep(1:B, each=2)
xs <- sapply(1:length(idx), function(b) if(b %% 2 == 0) idx[b] + 0.5 else idx[b] - 0.5)

obs <- hist(data$y, breaks=breaks, plot=FALSE)$counts
pad_obs <- do.call(cbind, lapply(idx, function(n) obs[n]))

post_pred <- sapply(1:4000, function(n) hist(samples$y_post_pred[n,], breaks=breaks, plot=FALSE)$counts)
probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:B, function(b) quantile(post_pred[b,], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

plot(1, type="n", main="Posterior Retrodictive Distribution",
     xlim=c(-0.5, B - 0.5), xlab="y",
     ylim=c(0, max(c(obs, cred[9,]))), ylab="")

polygon(c(xs, rev(xs)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = c_light, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = c_mid, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = c_mid_highlight, border = NA)
lines(xs, pad_cred[5,], col=c_dark, lwd=2)

lines(xs, pad_obs, col="white", lty=1, lw=2.5)
lines(xs, pad_obs, col="black", lty=1, lw=2)
```

We now finally consider the spatial heterogeneity within each detector as
encoded in Factor 3.  As always we start with a prior check.

```{r}
writeLines(readLines("stan_programs/batch_ver3_prior.stan"))
```

```{r}
data$factor1_cp_idx <- vector()
data$L_factor1_cp <- length(data$factor1_cp_idx)

data$factor1_ncp_idx <- setdiff(1:data$N_factor1_levels, data$factor1_cp_idx)
data$L_factor1_ncp <- length(data$factor1_ncp_idx)

data$factor2_cp_idx <- vector()
data$L_factor2_cp <- length(data$factor2_cp_idx)

data$factor2_ncp_idx <- setdiff(1:data$N_factor2_levels, data$factor2_cp_idx)
data$L_factor2_ncp <- length(data$factor2_ncp_idx)

data$factor3_cp_idx <- vector()
data$L_factor3_cp <- length(data$factor3_cp_idx)

data$factor3_ncp_idx <- setdiff(1:data$N_factor3_levels, data$factor3_cp_idx)
data$L_factor3_ncp <- length(data$factor3_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/batch_ver3_prior.stan',
            data=data, init_r=1, seed=4838282, refresh=1000)
```

```{r}
util$check_all_diagnostics(fit)
```

The tail on the calibration coefficients is starting to approach concern, with
increased mass not only as extreme values above 10 but also increased mass at
more moderately large values, such as those in the interval between 5 and 10.
Given the informativeness of the likelihood function in the previous models,
however, this prior model should be okay.  That said we'll have to remain
vigilant when investigating the posterior distribution for any signs of
unacceptably degenerate inferences.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1))

hist(exp(samples$log_psi[samples$log_psi < 4]),
     breaks=seq(0, 100, 0.25), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 25), xlab="Psi", yaxt='n', ylab="")
```

Our final Stan program incorporates the contributions to the heterogeneity in the
calibration coefficients from all three nested factors.

```{r}
writeLines(readLines("stan_programs/batch_ver3.stan"))
```

Because the Factor 2 hierarchical parameters performed well with a non-centered
parameterization the Factor 3 hierarchical parameters, which are even less
informed by the likelihood function, should also be suited to a non-centered
parameterization.

```{r}
data$factor1_cp_idx <- 1:data$N_factor1_levels
data$L_factor1_cp <- length(data$factor1_cp_idx)

data$factor1_ncp_idx <- setdiff(1:data$N_factor1_levels, data$factor1_cp_idx)
data$L_factor1_ncp <- length(data$factor1_ncp_idx)

data$factor2_cp_idx <- vector()
data$L_factor2_cp <- length(data$factor2_cp_idx)

data$factor2_ncp_idx <- setdiff(1:data$N_factor2_levels, data$factor2_cp_idx)
data$L_factor2_ncp <- length(data$factor2_ncp_idx)

data$factor3_cp_idx <- vector()
data$L_factor3_cp <- length(data$factor3_cp_idx)

data$factor3_ncp_idx <- setdiff(1:data$N_factor3_levels, data$factor3_cp_idx)
data$L_factor3_ncp <- length(data$factor3_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/batch_ver3.stan',
            data=data, init_r=1, seed=4838282, refresh=1000)
```

Indeed there are no hints of computational problems.

```{r}
util$check_all_diagnostics(fit)
```

But what about the posterior retrodictive checks?  It doesn't get much better
than this for the $F$ statistic, indicating that we've finally incorporated
enough variation in the calibration coefficients.  At least, that is, given the
resolution of the observed data.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 1))

hist(samples$F_post_pred, breaks=seq(3000, 7000, 50),
     main="Posterior Retrodictive Checks",
     col=c_dark, border=c_dark_highlight,
     xlim=c(3000, 7000), xlab="F Statistic", yaxt='n', ylab="")
abline(v=F_obs, col="white", lty=1, lw=3)
abline(v=F_obs, col="black", lty=1, lw=2)
```

At the same time posterior retrodiction distribution for the binned data now
aligns well with the observed histogram.  While there are various fluctuations
there are no systematic deviations that indicate serious model deficiencies.

```{r}
B <- 126
breaks <- seq(-0.5, B - 0.5, 1)

idx <- rep(1:B, each=2)
xs <- sapply(1:length(idx), function(b) if(b %% 2 == 0) idx[b] + 0.5 else idx[b] - 0.5)

obs <- hist(data$y, breaks=breaks, plot=FALSE)$counts
pad_obs <- do.call(cbind, lapply(idx, function(n) obs[n]))

post_pred <- sapply(1:4000, function(n) hist(samples$y_post_pred[n,], breaks=breaks, plot=FALSE)$counts)
probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:B, function(b) quantile(post_pred[b,], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

plot(1, type="n", main="Posterior Retrodictive Distribution",
     xlim=c(-0.5, B - 0.5), xlab="y",
     ylim=c(0, max(c(obs, cred[9,]))), ylab="")

polygon(c(xs, rev(xs)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = c_light, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = c_mid, border = NA)
polygon(c(xs, rev(xs)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = c_mid_highlight, border = NA)
lines(xs, pad_cred[5,], col=c_dark, lwd=2)

lines(xs, pad_obs, col="white", lty=1, lw=2.5)
lines(xs, pad_obs, col="black", lty=1, lw=2)
```

Confident in the adequacy of our model we can now start looking through the
posterior inferences, starting with the baseline parameter.

```{r}
par(mfrow=c(1, 1), mar=c(5, 1, 3, 1))

hist(samples$baseline, breaks=seq(-3, 3, 0.1), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(-3, 3), xlab="Baseline", yaxt='n', ylab="")
```

The posterior distribution for all of the calibration coefficients spans a
pretty wide range of values; if we were expecting precision instruments then we
might need to consider another supplier!  At the same time the clustering is
characteristic of the systematic trends across the nested factor levels.

```{r}
par(mfrow=c(1, 1), mar=c(5, 3, 3, 1))

hist(exp(samples$log_psi), breaks=seq(0, 1.25, 0.025), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 1.25), xlab="psi", yaxt='n', ylab="")
```

That said with our calibration data and full model we can separate the different
contributions to this heterogeneity relatively well.  First we can infer the
variation common to each shipment.

```{r, fig.height=4}
layout(matrix(c(1, 1, 2), nrow=1))

L <- data$N_factor1_levels
idx <- rep(1:L, each=2)
x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:L, function(l)
  quantile(samples$delta_factor1[,l], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

mean_tau <- mean(samples$delta_factor1_tau)

lb <- min(c(-2.25 * mean_tau, cred[1,]))
ub <- max(c(+2.25 * mean_tau, cred[9,]))

par(mar=c(5, 5, 3, 1))
plot(1, type="n", main="Shipment Heterogenity",
     xlim=c(0.5, L + 0.5), xlab="", xaxt="n",
     ylim=c(lb, ub), ylab="Marginal Posterior")

lines(c(0.5, L + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
lines(c(0.5, L + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
lines(c(0.5, L + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = c_light, border = NA)
polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = c_mid, border = NA)
polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = c_mid_highlight, border = NA)
for (l in 1:L)
  lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

axis(1, at=1:L, labels=sapply(1:L, function(l) paste("l1_", l, sep="")))

par(mar=c(5, 1, 3, 1))
u <- 1.25 * max(samples$delta_factor1_tau)
hist(samples$delta_factor1_tau, breaks=seq(0, u, u / 50), main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
abline(v=mean_tau, col="gray80", lwd=2, lty=3)
```

Then we can investigate the variations common to each detector.

```{r, fig.height=4}
for (l1 in 1:data$N_factor1_levels) {
  layout(matrix(c(1, 1, 2), nrow=1))

  level_idx <- which(data$factor2_to_factor1 == l1)
  L <- length(level_idx)
  idx <- rep(1:L, each=2)
  x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

  probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
  cred <- sapply(level_idx, function(l)
    quantile(samples$delta_factor2[,l], probs=probs))
  pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

  mean_tau <- mean(samples$delta_factor2_tau[,l1])

  lb <- min(c(-2.25 * mean_tau, cred[1,]))
  ub <- max(c(+2.25 * mean_tau,cred[9,]))

  title <- paste("Detector Heterogeneity Within Shipment", l1)

  par(mar=c(5, 5, 3, 1))
  plot(1, type="n", main=title,
       xlim=c(0.5, L + 0.5), xlab="", xaxt="n",
       ylim=c(lb, ub), ylab="Marginal Posterior")

  lines(c(0.5, L + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
  lines(c(0.5, L + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
  lines(c(0.5, L + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

  polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
          col = c_light, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
          col = c_light_highlight, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
          col = c_mid, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
          col = c_mid_highlight, border = NA)
  for (l in 1:L)
    lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

  axis(1, at=1:L, sapply(level_idx, function(l) paste("l2_", l, sep="")))

  par(mar=c(5, 1, 3, 1))
  u <- 1.25 * max(samples$delta_factor2_tau[,l1])
  hist(samples$delta_factor2_tau[,l1], breaks=seq(0, u, u / 50), main="",
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
  abline(v=mean_tau, col="gray80", lwd=2, lty=3)
}
```

Finally we learn the variations within each detector.

```{r, fig.height=4}
for (l2 in 1:data$N_factor2_levels) {
  layout(matrix(c(1, 1, 2), nrow=1))

  level_idx <- which(data$factor3_to_factor2 == l2)
  L <- length(level_idx)
  idx <- rep(1:L, each=2)
  x <- sapply(1:length(idx), function(l) if(l %% 2 == 0) idx[l] + 0.5 else idx[l] - 0.5)

  probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
  cred <- sapply(level_idx, function(l)
    quantile(samples$delta_factor3[,l], probs=probs))
  pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

  mean_tau <- mean(samples$delta_factor3_tau[,l2])

  lb <- min(c(-2.25 * mean_tau, cred[1,]))
  ub <- max(c(+2.25 * mean_tau, cred[9,]))

  title <- paste("Spatial Heterogeneity Within Detector", l2)

  par(mar=c(5, 5, 3, 1))
  plot(1, type="n", main=title,
       xlim=c(0.5, L + 0.5), xlab="", xaxt="n",
       ylim=c(lb, ub), ylab="Marginal Posterior")

  lines(c(0.5, L + 0.5), c(2 * mean_tau, 2 * mean_tau), col="gray80", lwd=3, lty=2)
  lines(c(0.5, L + 0.5), c(0, 0), col="gray80", lwd=3, lty=2)
  lines(c(0.5, L + 0.5), c(-2 * mean_tau, -2 * mean_tau), col="gray80", lwd=3, lty=2)

  polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
          col = c_light, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
          col = c_light_highlight, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
          col = c_mid, border = NA)
  polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
          col = c_mid_highlight, border = NA)
  for (l in 1:L)
    lines(x[(2*l-1):(2*l)], pad_cred[5,(2*l-1):(2*l)], col=c_dark, lwd=2)

  axis(1, at=1:L, sapply(level_idx, function(l) paste("l2_", l, sep="")))

  par(mar=c(5, 1, 3, 1))
  u <- 1.25 * max(samples$delta_factor3_tau[,l2])
  hist(samples$delta_factor3_tau[,l2], breaks=seq(0, u, u / 50), main="",
       col=c_dark, border=c_dark_highlight,
       xlim=c(0, u), xlab="Population Scale", yaxt='n', ylab="")
  abline(v=mean_tau, col="gray80", lwd=2, lty=3)
}
```

The detector performance may not be as consistent as we might have hoped, and
we still don't know why the performance varies so strongly.  These precise
inferences from the calibration data and the nested multifactor model, however,
does allow us individually calibrate each detector, correcting for the
heterogeneous behavior well enough that the detectors should be useful as more
than just door stops.

## Quality Assurance

Consider an industrial setting where we are responsible for understanding how
well a new manufacturing process performs in factories across the world.  This
manufacturing process consumes some input material to produce some manufactured
good, but the process isn't perfect.  With some probability a manufactured item
will fail quality assurance and have to be discarded.

One concern with this new process is that the probability of passing quality
assurance standards is expected to decay with time due to wear and tear on the
mechanical components of the new technology.  This decay, however, may not be
constant.  For example environmental factors at each factory location might
accelerate or decelerate the attrition of the machines.  Similarly the decay
might vary over the different maintenance methods used by different operators.
At the same time different sources of the input material might introduce
different contaminants that could influence the decay.

To get a handle on all of these contributions performance data have been
collected at multiple factories.


```{r}
data <- read_rdump('data/qa.data.R')

names(data)
```

In total the observations span `data$N_factor_configs = 250` different
configurations of the three observed factors -- `N_location = 9` different
factory locations, `N_method = 5` different maintenance methods, and
`N_source = 7` different sources of the input material.  The data collection was
designed to cover the levels in each of these main factors relatively uniformly,
although that may not be representative of the conditions under which the
process might be implemented in full production.

```{r}
par(mfrow=c(3, 1))
par(mar=c(5, 5, 3, 1))

hist(data$location_idx,
     breaks=seq(0.5, data$N_location + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_location + 0.5), xlab="Location Levels",
     ylim=c(0, 40), ylab="Number of\nObservations")

hist(data$method_idx,
     breaks=seq(0.5, data$N_method + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_method+ 0.5), xlab="Method Levels",
     ylim=c(0, 60), ylab="Number of\nObservations")

hist(data$source_idx,
     breaks=seq(0.5, data$N_source + 0.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(0.5, data$N_source + 0.5), xlab="Source Levels",
     ylim=c(0, 50), ylab="Number of\nObservations")
```

That said note that the 250 observed factor configurations are less than the
`N_locations * N_methods * N_sources = 360` full interaction levels.
Consequently we can't infer the behavior of each possible factor configuration
independently.

In each of the 250 contexts identical manufacturing equipment was installed and
measurements were taken about every three months over the course of a year of
production.  Each individual measurement applied quality assurance testing to
`N_samples = 25` items randomly selected from the production line, recording
the number of passing items `y`.

```{r}
par(mfrow=c(1, 3))

hist(data$y, breaks=seq(-0.5, 25.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(-0.5, 25.5), xlab="Passing Items",
     ylim=c(0, 100), yaxt='n', ylab="")

hist(data$t, breaks=seq(-10.5, 370.5, 1),
     main="", col=c_dark, border=c_dark_highlight,
     xlim=c(-10.5, 370.5), xlab="Observation Times\n(Days Since Installation)",
     ylim=c(0, 125), yaxt='n', ylab="")

plot(data$t, data$y, type="p", pch=16, col=c_dark,
     xlim=c(-10.5, 370.5), xlab="Observation Times\n(Days Since Installation)",
     ylim=c(-0.5, 25.5), ylab="Passing Items")
```

To facilitate fitting an overlapping multifactor model we have to organize the
three main factors into a matrix.

```{r}
data$N_main_factors <- 3
data$N_main_factor_levels <- c(data$N_location, data$N_method, data$N_source)
data$main_factor_level_idx <- rbind(data$location_idx, data$method_idx, data$source_idx)
```

Now we can programmatically construct the first and second-order interactions.

```{r, warning=FALSE, message=FALSE}
inter_data <-  NULL
inter_data$N <- data$N_factor_configs
inter_data$N_main_factors <- data$N_main_factors
inter_data$N_main_factor_levels <- data$N_main_factor_levels
inter_data$main_factor_level_idx <- data$main_factor_level_idx

inter <- stan(file='stan_programs/construct_inter_idx_general.stan',
              data=inter_data, iter=1, warmup=0, chains=1,
              algorithm="Fixed_param")

inter_output <- extract(inter)

data$N_inter1_factors <- inter_output$N_inter1_factors[1]
data$N_inter1_factor_levels <- array(inter_output$N_inter1_factor_levels[1,])
data$inter1_factor1_idx <- inter_output$inter1_factor1_idx[1,]
data$inter1_factor2_idx <- inter_output$inter1_factor2_idx[1,]
data$inter1_factor_level_idx <- inter_output$inter1_factor_level_idx[1,,]
dim(data$inter1_factor_level_idx) <- c(data$N_inter1_factors, data$N_factor_configs)

data$N_inter2_factors <- inter_output$N_inter2_factors[1]
data$N_inter2_factor_levels <- array(inter_output$N_inter2_factor_levels[1,])
data$inter2_factor1_idx <- inter_output$inter2_factor1_idx[1,]
data$inter2_factor2_idx <- inter_output$inter2_factor2_idx[1,]
data$inter2_factor3_idx <- inter_output$inter2_factor3_idx[1,]
data$inter2_factor_level_idx <- inter_output$inter2_factor_level_idx[1,,]
dim(data$inter2_factor_level_idx) <- c(data$N_inter2_factors, data$N_factor_configs)
```

While we're here let's give everything readable names.

```{r}
main_factor_names <- c("Location Factor", "Method Factor", "Source Factor")
inter1_factor_names <- c("Location/Method Factor", "Location/Source Factor", "Method/Source Factor")
inter2_factor_names <- c("Location/Method/Source Factor")
```

Finally we can pack all of the main and interaction factors into one-dimensional
arrays to facilitate specifying the overlapping factor models in Stan.

```{r}
pack <- stan(file='stan_programs/pack_idx.stan', data=data,
             iter=1, warmup=0, chains=1, algorithm="Fixed_param")

pack_output <- extract(pack)

data$N_all_main_factor_levels <- pack_output$N_all_main_factor_levels[1]
data$packed_main_factor_idx <- array(pack_output$packed_main_factor_idx[1,])
data$main_factor_start_idx <- array(pack_output$main_factor_start_idx[1,])
data$main_factor_end_idx <- array(pack_output$main_factor_end_idx[1,])

data$N_all_inter1_factor_levels <- pack_output$N_all_inter1_factor_levels[1]
data$packed_inter1_factor_idx <- array(pack_output$packed_inter1_factor_idx[1,])
data$inter1_factor_start_idx <- array(pack_output$inter1_factor_start_idx[1,])
data$inter1_factor_end_idx <- array(pack_output$inter1_factor_end_idx[1,])

data$N_all_inter2_factor_levels <- pack_output$N_all_inter2_factor_levels[1]
data$packed_inter2_factor_idx <- array(pack_output$packed_inter2_factor_idx[1,])
data$inter2_factor_start_idx <- array(pack_output$inter2_factor_start_idx[1,])
data$inter2_factor_end_idx <- array(pack_output$inter2_factor_end_idx[1,])
```

Before fitting an initial model we have to consider the summary statistics
appropriate for posterior retrodictive checks.  Our domain expertise suggests
that any heterogeneity should manifest in the rate of performance decay, but
it's not straightforward to construct summaries of the data that are
directly sensitive to the rate of decay, especially with the variable
measurement times.

One alternative is to look at measurements that were made on exactly the same
day.  By fixing the measurement time any heterogeneity in the decay will manifest
as heterogeneity in the number of passing items which will then increase the
value of the corresponding $F$ statistic.  Because most of the measurements are
made quarterly let's make posterior retrodictive checks every 90 days.

```{r}
data$N_checks <- 5

q0_obs <- which(data$t == 0)
q1_obs <- which(data$t == 90)
q2_obs <- which(data$t == 180)
q3_obs <- which(data$t == 270)
q4_obs <- which(data$t == 360)

data$N_check_obs <- min(c(length(q0_obs), length(q1_obs),
                          length(q2_obs), length(q3_obs),
                          length(q4_obs)))
data$check_idx <- matrix(0, nrow=data$N_checks, data$N_check_obs)
data$check_idx[1,] <- sample(q0_obs, data$N_check_obs)
data$check_idx[2,] <- sample(q1_obs, data$N_check_obs)
data$check_idx[3,] <- sample(q2_obs, data$N_check_obs)
data$check_idx[4,] <- sample(q3_obs, data$N_check_obs)
data$check_idx[5,] <- sample(q4_obs, data$N_check_obs)
```

By restricting the posterior retrodictive checks to the measurements collected
only on the same day we do limit how well we'll be able to resolve any deviant
behavior, especially with regard to the factor heterogeneity.

```{r}
writeLines(readLines("stan_programs/qa_f_stat.stan"))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/qa_f_stat.stan', data=data, seed=93585393,
            iter=1, warmup=0, chains=1, algorithm="Fixed_param")

F_main_obs <- extract(fit)$F_main_obs[1,,]
F_inter1_obs <- extract(fit)$F_inter1_obs[1,,]
F_inter2_obs <- extract(fit)$F_inter2_obs[1,,]
```

Now we're ready to start modeling.  Let's begin without any heterogeneity and
assume that the rate of decay is constant across all measurements.

Our domain expertise motivates high success probabilities upon installation with
significant decay possible over the course of a year.  To ensure that our prior
model is reasonable we can plot the evolution of the success probability for
model configurations sampled from the prior distribution.

```{r}
data$fine_t <- 10*(1:37)
data$N_fine_t <- length(data$fine_t)
```

```{r}
writeLines(readLines("stan_programs/qa_ver0_prior.stan"))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/qa_ver0_prior.stan',
            data=data, seed=4838282, refresh=2000)
```

```{r, cache=TRUE}
util$check_all_diagnostics(fit)
```

As is the case for any distribution over functions, we have to make a few
compromises when visualizing the prior pushforward distribution over the success
probability evolutions.  On the left we plot an ensemble of some of the
evolutions and on the right we plot marginal quantiles that provide a
quantification of the range of point-wise behaviors.

Neither demonstrates any behavior that strongly conflicts with our domain
expertise.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 2))

library(colormap)
nom_colors <- c("#DCBCBC", "#C79999", "#B97C7C", "#A25050", "#8F2727", "#7C0000")

plot_idx <- seq(1, 1000, 10)
N_plot <- length(plot_idx)
line_colors <- colormap(colormap=nom_colors, nshades=N_plot)

plot(1, type="n", main="Spaghetti",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
for (n in 1:N_plot)
  lines(data$fine_t, samples$p[plot_idx[n],], col=line_colors[n], lwd=2)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:data$N_fine_t, function(n) quantile(samples$p[,n], probs=probs))

plot(1, type="n", main="Quantile Ribbons",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[1,], rev(cred[9,])),
        col = c_light, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[2,], rev(cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[3,], rev(cred[7,])),
        col = c_mid, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[4,], rev(cred[6,])),
        col = c_mid_highlight, border = NA)
lines(data$fine_t, cred[5,], col=c_dark, lwd=2)
```

We then continue by incorporating the observational model and fitting the
corresponding posterior distribution.

```{r}
writeLines(readLines("stan_programs/qa_ver0.stan"))
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/qa_ver0.stan',
            data=data, seed=4838282, refresh=2000)
```

```{r, cache=TRUE}
util$check_all_diagnostics(fit)
```

The computation looks okay so let's run the posterior retrodictive checks.
Although these checks are not the most sensitive we do see a strong indication
of heterogeneity across the location levels.

```{r}
samples <- extract(fit)

par(mfrow=c(3, data$N_checks))
par(mar=c(5, 1, 3, 1))

lims <- c(200, 50, 50)

for (f in 1:3) {
  for (c in 1:data$N_checks) {
    title <- paste(main_factor_names[f], ",\n Check ", c, sep='')
    hist(samples$F_main_post_pred[, f, c], breaks=seq(0, 200, 1),
         main=title, col=c_dark, border=c_dark_highlight,
         xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
    abline(v=F_main_obs[f, c], col="white", lty=1, lw=3)
    abline(v=F_main_obs[f, c], col="black", lty=1, lw=2)       
  }
}
```

While we're suspicious of how well this model fits the observed data let's take
a minute to examine its posterior inferences.  The marginal posterior
distribution for both the logit intercept `\alpha` and the baseline strongly
contract from the prior model.

```{r}
par(mfrow=c(1, 2))

hist(samples$baseline, breaks=seq(-7, 1, 0.2),  main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(-7, 1), xlab="Baseline Logit Slope", yaxt='n', ylab="")

hist(samples$alpha, breaks=seq(1.75, 2.25, 0.01),  main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(1.75, 2.25), xlab="Logit Intercept", yaxt='n', ylab="")
```

This implies that only a relatively small set of the success probability
evolutions supported by the model are consistent with the observed data.

```{r}
par(mfrow=c(1, 2))
par(mar=c(5, 5, 3, 1))

N_plot <- 100
line_colors <- colormap(colormap=nom_colors, nshades=N_plot)
config_plot_idx <- rep(20*(1:10), each=10)
sample_plot_idx <- rep(400*(1:10), 10)

plot(1, type="n", main="Spaghetti",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
for (n in 1:N_plot)
  lines(data$fine_t, samples$p[sample_plot_idx[n], config_plot_idx[n],],
        col=line_colors[n], lwd=2)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:data$N_fine_t, function(n) quantile(samples$p[,,n], probs=probs))

plot(1, type="n", main="Quantile Ribbons",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[1,], rev(cred[9,])),
        col = c_light, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[2,], rev(cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[3,], rev(cred[7,])),
        col = c_mid, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[4,], rev(cred[6,])),
        col = c_mid_highlight, border = NA)
lines(data$fine_t, cred[5,], col=c_dark, lwd=2)
```

The posterior retrodictive checks, however, are worrisome, especially when
coupled with our domain expertise that factor heterogeneity is not unexpected.
Consequently let's consider a first-order model where we add the main factor
contributions.

Again we start with a prior pushforward check.

```{r}
writeLines(readLines("stan_programs/qa_ver1_prior.stan"))
```

We non-center the hierarchical parameters which are completely unconstrained by
observations in the prior model.

```{r}
data$main_cp_idx <- vector()
data$L_main_cp <- length(data$main_cp_idx)

data$main_ncp_idx <- setdiff(1:data$N_all_main_factor_levels, data$main_cp_idx)
data$L_main_ncp <- length(data$main_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/qa_ver1_prior.stan',
            data=data, seed=4838282, refresh=2000)
```

```{r, cache=TRUE}
util$check_all_diagnostics(fit)
```

By plotting a few prior samples for each of the sampled factor configurations
we see some clustering in the prior pushforward spaghetti plot, although that
substructure largely washes out in the marginal quantile ribbons.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 2))

N_plot <- 100
line_colors <- colormap(colormap=nom_colors, nshades=N_plot)
config_plot_idx <- rep(20*(1:10), each=10)
sample_plot_idx <- rep(400*(1:10), 10)

plot(1, type="n", main="Spaghetti",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
for (n in 1:N_plot)
  lines(data$fine_t, samples$p[sample_plot_idx[n], config_plot_idx[n],],
        col=line_colors[n], lwd=2)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:data$N_fine_t, function(n) quantile(samples$p[,,n], probs=probs))

plot(1, type="n", main="Quantile Ribbons",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[1,], rev(cred[9,])),
        col = c_light, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[2,], rev(cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[3,], rev(cred[7,])),
        col = c_mid, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[4,], rev(cred[6,])),
        col = c_mid_highlight, border = NA)
lines(data$fine_t, cred[5,], col=c_dark, lwd=2)
```

Either way the prior consequences look reasonable so we can continue on to the
posterior distribution.

```{r}
writeLines(readLines("stan_programs/qa_ver1.stan"))
```

Note that we maintain the non-centered parameterization that we used in the
prior fit.

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/qa_ver1.stan',
            data=data, seed=4838282, refresh=2000)
```

```{r, cache=TRUE}
util$check_all_diagnostics(fit)
```

With no indications of computational problems let's consult the posterior
retrodictive checks as we are wont to do.  Adding heterogeneity across the main
factors has resolved the posterior retrodictive discrepancy that we saw in the
previous model.

```{r}
samples <- extract(fit)

par(mfrow=c(3, data$N_checks))
par(mar=c(5, 1, 3, 1))

lims <- c(600, 50, 50)
deltas <- c(10, 1, 1)

for (f in 1:3) {
  for (c in 1:data$N_checks) {
    title <- paste(main_factor_names[f], ",\n Check ", c, sep='')
    hist(samples$F_main_post_pred[, f, c], breaks=seq(0, 1000, deltas[f]),
         main=title, col=c_dark, border=c_dark_highlight,
         xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
    abline(v=F_main_obs[f, c], col="white", lty=1, lw=3)
    abline(v=F_main_obs[f, c], col="black", lty=1, lw=2)
  }
}
```

The posterior retrodictive behavior across the first-order interaction factors
is harder to judge given the limited sensitivity of our summary statistic.
That said there are weak signs of trouble in the method/source interactions.

```{r}
par(mfrow=c(3, data$N_checks))
lims <- c(700, 700, 100)
deltas <- c(20, 20, 1)

for (f in 1:3) {
  for (c in 1:data$N_checks) {
    title <- paste(inter1_factor_names[f], ",\n Check ", c, sep='')
    hist(samples$F_inter1_post_pred[, f, c], breaks=seq(0, 3000, deltas[f]),
         main=title, col=c_dark, border=c_dark_highlight,
         xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
    abline(v=F_inter1_obs[f, c], col="white", lty=1, lw=3)
    abline(v=F_inter1_obs[f, c], col="black", lty=1, lw=2)
  }
}
```

Putting our model adequacy concerns to the side for a second let's take a look
at the posterior inferences for this model.

Note that the inferences for the baseline are now weaker -- this is not
surprising as the introduction of the main factor heterogeneity impedes the
direct influence of the data onto the baseline parameter.

```{r}
par(mfrow=c(1, 2))

hist(samples$baseline, breaks=seq(-7, 1, 0.2),  main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(-7, 1), xlab="Baseline Logit Slope", yaxt='n', ylab="")

hist(samples$alpha, breaks=seq(1.75, 2.25, 0.01),  main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(1.75, 2.25), xlab="Logit Intercept", yaxt='n', ylab="")
```

The posterior distribution definitely takes advantage of the heterogeneity
parameters, especially across the location levels.

```{r, fig.height=4}
plot_factor_posteriors("main", "Location Factor", 1)
plot_factor_posteriors("main", "Method Factor", 2)
plot_factor_posteriors("main", "Source Factor", 3)
```

The inferred heterogeneity across the main factor levels then manifests in
clustered success probability evolutions.

```{r}
par(mfrow=c(1, 2))
par(mar=c(5, 5, 3, 1))

N_plot <- 100
line_colors <- colormap(colormap=nom_colors, nshades=N_plot)
config_plot_idx <- rep(20*(1:10), each=10)
sample_plot_idx <- rep(400*(1:10), 10)

plot(1, type="n", main="Spaghetti",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
for (n in 1:N_plot)
  lines(data$fine_t, samples$p[sample_plot_idx[n], config_plot_idx[n],],
        col=line_colors[n], lwd=2)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:data$N_fine_t, function(n) quantile(samples$p[,,n], probs=probs))

plot(1, type="n", main="Quantile Ribbons",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[1,], rev(cred[9,])),
        col = c_light, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[2,], rev(cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[3,], rev(cred[7,])),
        col = c_mid, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[4,], rev(cred[6,])),
        col = c_mid_highlight, border = NA)
lines(data$fine_t, cred[5,], col=c_dark, lwd=2)
```

Can we do any better?  Let's add the first-order interaction factors and see
how much our fit improves, if at all.  First we have to ensure that the added
factors don't inflate our prior uncertainties to much.

```{r}
writeLines(readLines("stan_programs/qa_ver2_prior.stan"))
```

```{r}
data$main_cp_idx <- vector()
data$L_main_cp <- length(data$main_cp_idx)

data$main_ncp_idx <- setdiff(1:data$N_all_main_factor_levels, data$main_cp_idx)
data$L_main_ncp <- length(data$main_ncp_idx)

data$inter1_cp_idx <- vector()
data$L_inter1_cp <- length(data$inter1_cp_idx)

data$inter1_ncp_idx <- setdiff(1:data$N_all_inter1_factor_levels,
                               data$inter1_cp_idx)
data$L_inter1_ncp <- length(data$inter1_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/qa_ver2_prior.stan',
            data=data, seed=4838282, refresh=2000)
```

```{r, cache=TRUE}
util$check_all_diagnostics(fit)
```

While the prior pushforward distributions are a bit wider they're not so
inflated to be a concern.

```{r}
samples <- extract(fit)

par(mfrow=c(1, 2))

N_plot <- 100
line_colors <- colormap(colormap=nom_colors, nshades=N_plot)
config_plot_idx <- rep(20*(1:10), each=10)
sample_plot_idx <- rep(400*(1:10), 10)

plot(1, type="n", main="Spaghetti",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
for (n in 1:N_plot)
  lines(data$fine_t, samples$p[sample_plot_idx[n], config_plot_idx[n],],
        col=line_colors[n], lwd=2)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:data$N_fine_t, function(n) quantile(samples$p[,,n], probs=probs))

plot(1, type="n", main="Quantile Ribbons",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[1,], rev(cred[9,])),
        col = c_light, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[2,], rev(cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[3,], rev(cred[7,])),
        col = c_mid, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[4,], rev(cred[6,])),
        col = c_mid_highlight, border = NA)
lines(data$fine_t, cred[5,], col=c_dark, lwd=2)
```

And the posterior distribution?

```{r}
writeLines(readLines("stan_programs/qa_ver2.stan"))
```

```{r}
data$main_cp_idx <- vector()
data$L_main_cp <- length(data$main_cp_idx)

data$main_ncp_idx <- setdiff(1:data$N_all_main_factor_levels, data$main_cp_idx)
data$L_main_ncp <- length(data$main_ncp_idx)

data$inter1_cp_idx <- vector()
data$L_inter1_cp <- length(data$inter1_cp_idx)

data$inter1_ncp_idx <- setdiff(1:data$N_all_inter1_factor_levels, data$inter1_cp_idx)
data$L_inter1_ncp <- length(data$inter1_ncp_idx)
```


```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/qa_ver2.stan',
            data=data, seed=4838282, refresh=2000)
```

In the words of the great philosopher Cathy: ACK!.

```{r, cache=TRUE}
util$check_all_diagnostics(fit)
```

We don't get discouraged but instead diligently track those divergences down.

```{r}
partition <- util$partition_div(fit)
div_samples <- partition[[1]]
nondiv_samples <- partition[[2]]
```

With only three divergent transitions we'll have to consider the geometry of the
non-divergent samples just as much as the divergent samples.  Within the
location factor the level 4 parameter looks a bit more extended than the rest.

```{r}
f <- 1
par(mfrow=c(3, 3))
par(mar=c(5, 5, 3, 1))

for (l in data$main_factor_start_idx[f]:data$main_factor_end_idx[f]) {
  if (l %in% data$main_cp_idx) {
    cp_idx <- which(l == data$main_cp_idx)
    name_x <- paste("packed_delta_main_cp[", cp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  } else {
    ncp_idx <- which(l == data$main_ncp_idx)
    name_x <- paste("packed_delta_main_ncp[", ncp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  }

  title=paste(main_factor_names[f],
              ",\nLevel = ", l - data$main_factor_start_idx[f] + 1, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-5, 5),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-2, 2))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

The method factor level parameters look better behaved in comparison.

```{r}
f <- 2
par(mfrow=c(2, 3))

for (l in data$main_factor_start_idx[f]:data$main_factor_end_idx[f]) {
  if (l %in% data$main_cp_idx) {
    cp_idx <- which(l == data$main_cp_idx)
    name_x <- paste("packed_delta_main_cp[", cp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  } else {
    ncp_idx <- which(l == data$main_ncp_idx)
    name_x <- paste("packed_delta_main_ncp[", ncp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  }

  title=paste(main_factor_names[f],
              ",\nLevel = ", l - data$main_factor_start_idx[f] + 1, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-5, 5),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-9, 2))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

As do the source factor level parameters.

```{r}
f <- 3
par(mfrow=c(3, 3))

for (l in data$main_factor_start_idx[f]:data$main_factor_end_idx[f]) {
  if (l %in% data$main_cp_idx) {
    cp_idx <- which(l == data$main_cp_idx)
    name_x <- paste("packed_delta_main_cp[", cp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  } else {
    ncp_idx <- which(l == data$main_ncp_idx)
    name_x <- paste("packed_delta_main_ncp[", ncp_idx, "]", sep='')
    name_y <- paste("delta_main_tau[", data$packed_main_factor_idx[l], "]", sep='')
  }

  title=paste(main_factor_names[f],
              ",\nLevel = ", l - data$main_factor_start_idx[f] + 1, sep='')

  plot(nondiv_samples[name_x][,1], log(nondiv_samples[name_y][,1]),
       col=c_dark_trans, pch=16, main=title,
       xlab=name_x, xlim=c(-5, 5),
       ylab=paste("log(", name_y, ")", sep=''), ylim=c(-11, 1))
  points(div_samples[name_x][,1], log(div_samples[name_y][,1]),
         col=c_green_trans, pch=16)
}
```

Let's try centering just the parameter for the fourth level of the location
factor.

```{r}
data$main_cp_idx <- array(4)
data$L_main_cp <- length(data$main_cp_idx)

data$main_ncp_idx <- setdiff(1:data$N_all_main_factor_levels, data$main_cp_idx)
data$L_main_ncp <- length(data$main_ncp_idx)

data$inter1_cp_idx <- vector()
data$L_inter1_cp <- length(data$inter1_cp_idx)

data$inter1_ncp_idx <- setdiff(1:data$N_all_inter1_factor_levels, data$inter1_cp_idx)
data$L_inter1_ncp <- length(data$inter1_ncp_idx)
```

```{r, cache=TRUE, cache.lazy = FALSE, warning=FALSE, message=FALSE}
fit <- stan(file='stan_programs/qa_ver2.stan',
            data=data, seed=4838282, refresh=2000)
```

Delightfully that seems to have done the trick.

```{r, cache=TRUE}
util$check_all_diagnostics(fit)
```

Now we can investigate the posterior retrodictive behavior.  We don't see any
significant deviations across the main factor levels for any of the check times.

```{r}
samples <- extract(fit)

par(mfrow=c(3, data$N_checks))
par(mar=c(5, 1, 3, 1))

lims <- c(300, 50, 50)
delta <- c(5, 1, 1)

for (f in 1:3) {
  for (c in 1:data$N_checks) {
    title <- paste(main_factor_names[f], ",\n Check ", c, sep='')
    hist(samples$F_main_post_pred[, f, c], breaks=seq(0, 1000, delta[f]),
         main=title, col=c_dark, border=c_dark_highlight,
         xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
    abline(v=F_main_obs[f, c], col="white", lty=1, lw=3)
    abline(v=F_main_obs[f, c], col="black", lty=1, lw=2)
  }
}
```

Same for the first-order interactions.

```{r}
par(mfrow=c(3, data$N_checks))
lims <- c(500, 700, 100)

for (f in 1:3) {
  for (c in 1:data$N_checks) {
    title <- paste(inter1_factor_names[f], ",\n Check ", c, sep='')
    hist(samples$F_inter1_post_pred[, f, c], breaks=seq(0, 3000, 2),
         main=title, col=c_dark, border=c_dark_highlight,
         xlim=c(0, lims[f]), xlab="F Statistic", yaxt='n', ylab="")
    abline(v=F_inter1_obs[f, c], col="white", lty=1, lw=3)
    abline(v=F_inter1_obs[f, c], col="black", lty=1, lw=2)
  }
}
```

Indeed there's no signs of problems across the second-order interaction levels,
either.  This doesn't mean that heterogeneity across the second-order
interaction factors is negligible, however, just that the heterogeneity can't be
resolved by our relatively inefficient summary statistics.

```{r}
par(mfrow=c(1, data$N_checks))

for (f in 1:1) {
  for (c in 1:data$N_checks) {
    title <- paste("Check ", c, sep='')
    s <- samples$F_inter2_post_pred[, f, c]
    hist(s[is.finite(s)], breaks=seq(0, 200000, 1000),
         main=title, col=c_dark, border=c_dark_highlight,
         xlim=c(0, 25000), xlab="F Statistic", yaxt='n', ylab="")
    abline(v=F_inter2_obs[c], col="white", lty=1, lw=3)
    abline(v=F_inter2_obs[c], col="black", lty=1, lw=2)
  }
}

mtext(inter2_factor_names[f], outer = TRUE)
```

To confirm that the second-order interactions are not important within the
context of this measurement we could try fitting one more model that includes
the second-order interaction factor and see if the posterior distribution
concentrates away from zero.  Here, however, let's be satisfied with the
current model.

Filled with satisfaction let's explore the posterior distribution.  The marginal
posterior distributions for the baseline and logit intercept parameters haven't
changed much.

```{r}
par(mfrow=c(1, 2))

hist(samples$baseline, breaks=seq(-7, 1, 0.2),  main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(-7, 1), xlab="Baseline Logit Slope", yaxt='n', ylab="")

hist(samples$alpha, breaks=seq(1.75, 2.25, 0.01),  main="",
     col=c_dark, border=c_dark_highlight,
     xlim=c(1.75, 2.25), xlab="Logit Intercept", yaxt='n', ylab="")
```

The heterogeneity across the location and method factors remains large but note
that the inferred heterogeneity across the source factor levels is now
consistent with no heterogeneity at all!

```{r, fig.height=4}
plot_factor_posteriors("main", "Location Factor", 1)
plot_factor_posteriors("main", "Method Factor", 2)
plot_factor_posteriors("main", "Source Factor", 3)
```

On the other hand the heterogeneity across the method/source interaction factors
is substantial, specially between Maintenance Method 5 and Input Material Source
3!  Although technically just a measure of heterogeneity, this large interaction
_could_ indicate something important about the functionality of the
manufacturing process.  For example the lack of a common contaminant in Input
Material Source 3 might be compensating for Maintenance Method 5 being unable to
properly remove that contaminant.

```{r, fig.height=4}
plot_factor_posteriors("inter1", "Location/Method Interaction Factor", 1)
plot_factor_posteriors("inter1", "Location/Source Interaction Factor", 2)
plot_factor_posteriors("inter1", "Method/Source Interaction Factor", 3)
```

The significant change in behavior within main factor levels after the
introduction of interaction factors is common when the heterogeneity across
those interaction factor levels is large.  In particular when the interaction
factors are not included the main factor level parameters have to contort to
try to accommodate for the excess heterogeneity.  That particular contortion,
however, will depend on particular factor configurations observed and hence
will tend to generalize poorly to other factor configurations.  By explicitly
modeling the significant interactions we avoid this fragile contortion and
achieve much better generalizability, at least provided that whatever causes
the heterogeneity is static.

With the first-order interactions providing a reasonable fit to the total
heterogeneity we see the full variation of success probability evolutions.

```{r}
par(mfrow=c(1, 2))
par(mar=c(5, 5, 3, 1))

N_plot <- 100
line_colors <- colormap(colormap=nom_colors, nshades=N_plot)
config_plot_idx <- rep(20*(1:10), each=10)
sample_plot_idx <- rep(400*(1:10), 10)

plot(1, type="n", main="Spaghetti",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
for (n in 1:N_plot)
  lines(data$fine_t, samples$p[sample_plot_idx[n], config_plot_idx[n],],
        col=line_colors[n], lwd=2)

probs = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:data$N_fine_t, function(n) quantile(samples$p[,,n], probs=probs))

plot(1, type="n", main="Quantile Ribbons",
     xlab="time (days)", ylab="Success Probability",
     xlim=c(0, 365), ylim=c(0, 1))
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[1,], rev(cred[9,])),
        col = c_light, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[2,], rev(cred[8,])),
        col = c_light_highlight, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[3,], rev(cred[7,])),
        col = c_mid, border = NA)
polygon(c(data$fine_t, rev(data$fine_t)), c(cred[4,], rev(cred[6,])),
        col = c_mid_highlight, border = NA)
lines(data$fine_t, cred[5,], col=c_dark, lwd=2)
```

One of the powerful features of overlapping factor models is that we can
reconstruct the behavior of factor configurations that we didn't actually
observe.  With only 250 observed factor configurations there are many possible
combinations of the main factor levels that we did not yet observe.

```{r}
all_inter2_idx <- 1:data$N_all_inter2_factor_levels
obs_inter2_idx <- strtoi(names(table(data$inter2_factor_level_idx)))
setdiff(all_inter2_idx, obs_inter2_idx)
```

For example we didn't observe the second-order interaction level `311` which
corresponds to Factor Location 9, Maintenance Method 5, and Input Material
Source 3.

```{r}
decode_inter2_idx <- function(idx, data) {
  N1 <- data$N_main_factor_levels[1]
  N2 <- data$N_main_factor_levels[2]
  N3 <- data$N_main_factor_levels[3]

  location_idx <- (idx - 1) %/% (N2 * N3) + 1
  method_idx <- ( (idx - 1) %% (N2 * N3)) %/% N3 + 1
  source_idx <- ( (idx - 1) %% (N2 * N3)) %% N3 + 1

  c(location_idx, method_idx, source_idx)
}

main_factor_idx <- decode_inter2_idx(311, data)

main_factor_idx
```

Given that we didn't observe this particular configuration what might we predict
for its behavior after 300 days?  We could take a counterfactual approach that
ignores the heterogeneity entirely, basing our predictions on the baseline
behavior only.

```{r}
base_inf <- 1 / (1 + exp(-(samples$alpha + samples$baseline * 300 / 365.0)))

par(mfrow=c(1, 1))

hist(base_inf, breaks=seq(0, 1, 0.01),  main="Baseline Inference",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 1), xlab="Inferred Success Probability", yaxt='n', ylab="")
```

Alternatively we can reconstruct the behavior from the behavior common to
lower-order factor configurations that we did observe.  Although we didn't
observe Factor Location 9, Maintenance Method 5, and Input Material
Source 3 together, we did observe many configurations where each main factor
level appeared separately; we also observed plenty of configurations where the
levels of two of the main factors matched.  Because the overlapping multifactor
model separated these contributions we are able to add them back together in
different ways.

```{r}
encode_inter1 <- function(f1, l1, f2, l2, data) {
  (l1 - 1) * data$N_main_factor_levels[f2] + l2
}

inter1_12_idx <- encode_inter1(1, main_factor_idx[1], 2, main_factor_idx[2], data)
inter1_13_idx <- encode_inter1(1, main_factor_idx[1], 3, main_factor_idx[3], data)
inter1_23_idx <- encode_inter1(2, main_factor_idx[2], 3, main_factor_idx[3], data)

slope <- samples$baseline +
         samples$packed_delta_main[data$main_factor_start_idx[1] + main_factor_idx[1] - 1] +
         samples$packed_delta_main[data$main_factor_start_idx[2] + main_factor_idx[2] - 1] +
         samples$packed_delta_main[data$main_factor_start_idx[3] + main_factor_idx[3] - 1] +
         samples$packed_delta_inter1[data$inter1_factor_start_idx[1] + inter1_12_idx - 1] +
         samples$packed_delta_inter1[data$inter1_factor_start_idx[2] + inter1_13_idx - 1] +
         samples$packed_delta_inter1[data$inter1_factor_start_idx[3] + inter1_23_idx - 1]

recon_inf <- 1 / (1 + exp(-(samples$alpha + slope * 300 / 365.0)))

par(mfrow=c(1, 2))

hist(base_inf, breaks=seq(0, 1, 0.01),  main="Baseline Inference",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 1), xlab="Inferred Success Probability", yaxt='n', ylab="")

hist(recon_inf, breaks=seq(0, 1, 0.01),  main="Reconstructed Heterogeneity Inference",
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 1), xlab="Inferred Success Probability", yaxt='n', ylab="")
```

Ignoring the factor heterogeneity entirely yields a very different prediction
for the success probability of this unobserved factor configuration after 300
days.  The reconstruction based on a first-order interaction model might not be
perfect but it should provide much better predictions whenever the latent
process that generates the factor heterogeneities remains the same.

# What's In A Name?

One of the practical complications of using factor models is the -- perhaps
appropriate -- heterogeneity in terminology across, and even sometimes within,
different fields.  Indeed while the term "factor model" is directly motivated by
the basic assumption of heterogeneity across factor levels it is not all that
common in the contemporary applied statistics literature.  In this section I
will attempt to review some of the more common terminologies, and why I try to
avoid them.

In this case study I use "factor model" to refer to models with known level
assignments, but in some fields the term is also used to refer to models with
unknown level assignments, such as independent component analysis
[@Bishop:2006].  Any confusion here can be avoided by explicitly denoting
whether the factors, and the factor level assignments, are given or are meant to
be inferred from data.

The term "multilevel" is often associated with factor models, sometimes to the
point of being treated as synonyms.  Historically, however, "multilevel"
referred not to factor models in particular but rather to hierarchical models in
general with the "levels" denoting to the layers of the hierarchy, such as the
individual parameters verses the population parameters.  From this perspective
the term "multilevel" might indicate that hierarchical models are used, but
because it doesn't tell us how they are used it is not sufficient for denoting
factor models in particular.  Moreover the overloading of "level" to refer to
both the hierarchical structure _and_ the categorical values within each factor
is, in my opinion, far too confusing to be worth the risk.

Another term in the orbit of factor models is "random effect" and
"fixed effect".  Although there is some variation in applied literatures, in
classical statistics "random effect" denotes factor level parameters that are
modeled hierarchically while "fixed effect" denotes factor level parameter
modeled independently.  In other words a "random effect" implies a single factor
hierarchical model as defined in [Section 1.3](#sec:single_factor_model).
Similarly the term "random effects model" denotes models with multiple random
effects and "mixed effects models" denotes models with some random effects and
some fixed effects, although neither term indicates _how_ the effects are
integrated together.  Better is the term "additive model" or more precisely
"additive mixed effects model" which indicates that multiple random effects
corresponding to different factors, including main factors and their derived
interactions, are added together as in the residual expansions of nested
multifactor model and overlapping multifactor models.  Moreover the term
"additive mixed effects model" almost always implies that the residual expansion
is used to model the location parameter of some family of probability density
functions; when the observational model is not specified by a family of normal
density functions the term "general additive model" is also common.

Many contemporary tools such as `lme4` and `brms` use a _formula notation_ for
specifying these models of heterogeneity in a location parameter.  The notation
was initially introduced in @WilkinsonEtAl:1973 but it has since enjoyed its own
[storied evolution](https://stats.stackexchange.com/questions/284913/the-origin-of-the-wilkinson-style-notation-such-as-1id-for-random-effects-in/285026#285026).

My main issue with the "effect" terminology is the hidden, restrictive
assumptions that are often taken for granted.  For one the term "effect" itself
is loaded, implying a causal influence of each factor level that is not actually
implied by the mathematical model of heterogeneity.  Moreover the commonly
applied restriction to location parameters drastically limits the utility of
multifactor models which can be used to model the heterogeneity that manifests
in _any_ part of a probabilistic model.  Even within the implied assumptions
this terminology obfuscates the implementation of the model, in particular the
parameterization of the hierarchical models which is critical to accurate but
efficient computation.

To avoid terminological baggage and communicate the assumptions as clearly as
possible I prefer the terms "hierarchcial nested multifactor model" and
"hierarchical overlapping multifactor model" depending on the relationship
between the factors.  That said the best way to communicate the assumptions is
to document the full model.  One of the advantages of probabilistic programming
in Stan is that we have the flexibility to incorporate multifactor modeling
where ever it is motivated by the application, and the program itself
unambiguously communicates all of the assumptions being made; well-documented
programs even ensure that those assumptions are actually decipherable by
collaborators and colleagues.  The expressiveness of the language also allows
the parameterization of the many hierarchical models to be properly tuned to
avoid computational problems, as we have done in the above exercises.

Even if the full modeling flexibility isn't needed, the exercise of building
these models in Stan can be extremely useful for helping one to identify
assumptions that they may have been accidentally taking for granted.

# Conclusion

Factor models provide a principled approach to modeling heterogeneity compatible
not just with one categorizing factor but multiple nested or even overlapping
factors.  With this approach we can model complex experimental side effects and
isolate latent phenomena of interest in our inferences, and we can even
heuristically model the phenomena itself by how it manifests in variation within
the included factors.  When sufficient care is taken to ensure that the
the limitations of this modeling technique are understood and investigated,
factor models become a powerful addition to our modeling technique toolbox.

By building multifactor models ourselves in Stan we not only facilitate those
investigations but also free the technique from the restrictive assumptions
built into higher-level tools, allowing us to witness the full potential of
this fully armed and operational modeling technique.

# Acknowledgements {-}

I thank Jessica Graves and Charles Margossian for valuable comments.

A very special thanks to everyone supporting me on Patreon: Aapeli Nevala,
Abhinav Katoch, Abhishek Vasu, Adam Bartonicek, Adam Fleischhacker,
Adam Golinski, Adan, Alan O'Donnell, Alex ANDORRA, Alexander Bartik,
Alexander Noll, Alfredo Garbuno Iigo, Allison M. Campbell, Anders Valind,
Andrea Serafino, Andrew Rouillard, Annie Chen, Anthony Wuersch, Antoine Soubret,
Arya, asif zubair, Austin Carter, Austin Rochford, Austin Rochford,
Avraham Adler, Bao Tin Hoang, Ben Matthews, Ben Swallow, Benjamin Phillabaum,
enoit Essiambre, Bo Schwartz Madsen, Brian Hartley, Bryan Yu,
Brynjolfur Gauti Jnsson, Cameron Smith, Canaan Breiss, Cat Shark,
Chad Scherrer, Charles Naylor, Chase Dwelle, Chris Jones, Chris Zawora,
Christopher Mehrvarzi, Chuck Carlson, Cole Monnahan, Colin Carroll,
Colin McAuliffe, D, Damien Mannion, dan mackinlay, dan muck, Dan W Joyce,
Daniel Hocking, Daniel Rowe, Darshan Pandit, David Burdelski, David Christle,
David Humeau, David Pascall, Derek G Miller, Diogo Melo, Donna Perry,
Doug Rivers, Dylan Murphy, Ed Berry, Ed Cashin, Elizaveta Semenova, Eric Novik,
Erik Banek, Ero Carrera, Ethan Goan, Evan Cater, Fabio Zottele,
Federico Carrone, Felipe Gonzlez, Fergus Chadwick, Filipe Dias, Finn Lindgren,
Florian Wellmann, Francesco Corona, Geoff Rollins, George Ho, Georgia S,
Gerardo Salazar, Granville Matheson, Guido Biele, Guilherme Marthe,
Hamed Bastan-Hagh, Hany Abdulsamad, Haonan Zhu, Hugo Botha, Hyunji Moon, Ian,
Ignacio Vera, Ilaria Prosdocimi, Isaac S, J, J Michael Burgess,
Jair Andrade Ortiz, James McInerney, James Wade, JamesU, Janek Berger,
Jason Martin, Jeff Dotson, Jeff Helzner, Jeffrey Arnold, Jeffrey Burnett,
Jessica Graves, Joel Kronander, John Flournoy, John Zito, Jon , Jonathan Sedar,
Jonathan St-onge, Jonathon Vallejo, Jose Pereira, Josh Weinstock, Joshua Duncan,
Joshua Griffith, Joshua Mayer, Joss Wright, Josu Mendoza, Justin Bois,
Karim Naguib, Karim Osman, Kazuki Yoshida, Kejia Shi, Kdr Andrs,
Leo Grinsztajn, lizzie , Luiz Carvalho, Lukas Neugebauer, Marc Dotson,
Marc Trunjer Kusk Nielsen, Marek Kwiatkowski, Mark Donoghoe, Markus P.,
Martin Modrk, Matt Wescott, Matthew Kay, Matthew Quick, Matthew T Stern,
Maurits van der Meer, Maxim Kesin, Merlin Noel Heidemanns, Michael Colaresi,
Michael DeWitt, Michael Dillon, Michael Lerner, Michael Redman, Michael Tracy,
Mick Cooney, Miguel de la Varga, Mike Lawrence, Mikhail Popov, MisterMentat,
Mohammed Charrout, Mrton Vaitkus, Name, Nathan Rutenbeck, Nerf-Shepherd,
Nicholas Cowie, Nicholas Ursa, Nick S, Nicolas Frisby, Noah Guzman,
Octavio Medina, Ole Rogeberg, Oliver Crook, Olivier Ma, Omri Har Shemesh,
Pablo Len Villagr, Patrick Boehnke, Pau Pereira Batlle, Paul Oreto,
Peter Smits, Pieter van den Berg , Pintaius Pedilici, Ravin Kumar, Reed Harder,
Riccardo Fusaroli, Richard Price, Robert Frost, Robert Goldman, Robert J Neal,
Robert kohn, Robert Mitchell V, Robin Taylor, Rong Lu, Roofwalker,
Ryan Grossman, Rmi , Scott Block, Sean Talts, Seth Axen, Shira , sid phani,
Simon Dirmeier, Simon Duane, Simon Lilburn, Srivatsa Srinath,
Stephanie Fitzgerald, Stephen Lienhard, Stephen Oates, Steve Bertolani, Stijn,
Stone Chen, Sus, Susan Holmes, Suyog Chandramouli, Sren Berg, tardisinc,
Teddy Groves, Teresa Ortiz, Thomas Littrell, Thomas Vladeck, Tho Galy-Fajou,
Tiago Cabao, Tim Howes, Tim Radtke, Tobychev , Tom Knowles, Tom McEwen,
Tommy Naugle, Tuan Nguyen Anh, Tyrel Stokes, Utku Turk, Virginia Webber,
vittorio trotta, Vladimir Markov, Will Dearden, Will Farr, yolhaj, yureq, Z,
Zach A, and ZAKH.

# References {-}

<div id="refs"></div>

# License {-}

A repository containing the material used in this case study is available on
[GitHub](https://github.com/betanalpha/knitr_case_studies/tree/master/factor_modeling).

The code in this case study is copyrighted by Michael Betancourt and licensed
under the new BSD (3-clause) license:

https://opensource.org/licenses/BSD-3-Clause

The text and figures in this case study are copyrighted by Michael Betancourt
and licensed under the CC BY-NC 4.0 license:

https://creativecommons.org/licenses/by-nc/4.0/

# Original Computing Environment {-}

```{r}
writeLines(readLines(file.path(Sys.getenv("HOME"), ".R/Makevars")))
```

```{r}
sessionInfo()
```
